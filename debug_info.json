{
  "execution_time": "0:00:07.853070",
  "steps": [
    "extract_text",
    "process_text"
  ],
  "results": {
    "extract_text": "Raju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024\nScience Adv AnceS  | ReSeAR ch AR ticle\n1 of 16NEUROSCIENCE\nSpace is a latent sequence: A theory of \nthe hippocampus\nRajkumar Vasudeva Raju, J. Swaroop Guntupalli, Guangyao Zhou, Carter Wendelken,  \nMiguel L\u00e1zaro-  Gredilla, Dileep George*\nFascinating phenomena such as landmark vector cells and splitter cells are frequently discovered in the hippo -\ncampus. Without a unifying principle, each experiment seemingly uncovers new anomalies or coding types. Here, \nwe provide a unifying principle that the mental representation of space is an emergent property of latent higher- \norder sequence learning. Treating space as a sequence resolves numerous phenomena and suggests that the \nplace field mapping methodology that interprets sequential neuronal responses in Euclidean terms might itself \nbe a source of anomalies. Our model, clone- structured causal graph (CSCG), employs higher-  order graph scaffold-\ning to learn latent representations by mapping aliased egocentric sensory inputs to unique contexts. Learning to \ncompress sequential and episodic experiences using CSCGs yields allocentric cognitive maps that are suitable for \nplanning, introspection, consolidation, and abstraction. By explicating the role of Euclidean place field mapping \nand demonstrating how latent sequential representations unify myriad observed phenomena, our work positions \nthe hippocampus in a sequence-  centric paradigm, challenging the prevailing space-  centric view.\nINTRODUCTION\nThe hippocampus is known for its role in episodic memory, map- like \nspatial representations, relational inference, and fast learning\u2014a \nseemingly disparate set of requirements. Simultaneously, hippocam-\npal cells are categorized into a wide variety of types based on their \nfiring patterns ranging from place cells, splitter cells, time cells, lap \ncells, and event- specific representations and exhibit a variety of re-\nmapping phenomena in response to environmental changes (1 ). \nThese phenomena often get characterized using Euclidean spatial \nconcepts such as object vector cells (2 ), landmark vector cells (3 ), and \ndistance coding (3 , 4), without a coherent underlying explanation, \nand remain unresolved with other phenomena like splitter cells (5 \u20137) \nand event- specific representations (8 ). Could these divergent require-\nments and myriad phenomena be explained using a simple set of \nprinciples that are computationally grounded, implemented, and easy \nto understand? Here, we show that treating space as a sequence can \nresolve many of the divergent phenomena ascribed to spatial map-\nping, and help clarify the connections between spatial, temporal, ab-\nstract, and relational representations in the hippocampal complex.\nTreating space as a sequence is a necessity for humans and other \nanimals because they lack a global positioning system that enables \ndirect sensing of location coordinates. Additionally, their actions are \nnot with respect to a global coordinate frame as determined by a \ncompass. Consequently, they need to acquire and abstract the con-\ncepts of locations and space from purely egocentric sensory- motor \nexperience ( 9). However, sensations from the world are aliased (10, \n11) and do not convey locations directly. In other words, identical \nsensations can occur at multiple locations or in different sequential \ncontexts. Further complicating matters, an animal\u2019s actions are rela-\ntive to its body rather than to a global coordinate frame. To develop \ninternal space- like maps from these aliased sensations and egocen-\ntric actions (as illustrated in the sketch in Fig.\u00a01A), the learning agent \nhas to appropriately split or merge sensations based on sequential \ncontexts (Fig.\u00a01B) (12, 13). Our model, clone- structured causal graph (CSCG), tackles this problem by learning different latent states \n(called clones) to represent the same observation in different sequen-\ntial contexts (14\u2013 16), merging or splitting the latent states as neces-\nsary. In CSCGs, allocentric \u201cspatial\u201d representations naturally arise \nfrom higher- order sequence learning on egocentric sensory and mo-\ntor inputs, without making any Euclidean assumptions, and without \nhaving locations as an input. An organism or an agent can use a \nCSCG for navigation, foraging, context recognition, and shortcut \nplanning without having to explicitly compute place fields or having \nto decode locations.\nOur model suggests that place field maps need to be interpreted \ncarefully because they overlay sequential responses onto Euclidean \nmaps. Directly characterizing the place field maps in terms of spatial \nand Euclidean concepts could be a source of anomalies since the un-\nderlying phenomena are inherently sequential and dynamic ( 17). In \ncontrast, CSCG explicates how the learning of sequential contexts gives \nrise to spatial representations that an agent can use to drive behavior \nwithout explicitly representing location coordinates. CSCGs predict \nthe conditions under which place fields are expected to change in re-\nsponse to visible or invisible environmental changes, and when they do \nnot, resolving a variety of phenomena with a simple principle.\nModel\nWe consider experimental setups where an agent moves around in \nan environment and receives local sensations that are aliased in the \nsense that they do not correspond uniquely to locations in the envi-\nronment, and the actions of the agent are relative to its current ori-\nentation and not in a global frame. The environment need not be \nEuclidean. The agent makes no Euclidean assumptions and does not \nhave access to a map of the environment. If the sensations from the \nenvironment are vectors (for example, visual patterns) in a continu-\nous space, they are discretized using a vector quantizer. From a se-\nquence of discretized observations and actions, both of which could \nbe egocentric, an agent has to discover the latent topology of its en-\nvironment to vicariously evaluate different options for navigation. \nThis is a difficult problem due to the aliasing of the observations, \negocentric action space, and a lack of Euclidean assumptions.Google d eepMind, Mountain view, c A 94043, USA.\n*corresponding author. email: dileepgeorge@ google. comcopyright \u00a9 2024 the \nAuthors, some rights \nreserved; exclusive \nlicensee American \nAssociation for the \nAdvancement of \nScience. no claim to \noriginal U.S. \nGovernment Works. \ndistributed under a \ncreative c ommons \nAttribution \nnonc ommercial \nlicense 4.0 ( cc BY- nc ). \nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n2 of 16This can be formulated as the problem of learning a latent graph \nfrom aliased observations at its nodes. An agent performs a se-\nquence of actions a 1, \u2026, a N (with each a n \u2208 {1, \u2026, N actions }) in an \nenvironment G. As a result of each action, it receives an observation, \nobtaining the stream x 1, \u2026, x N (with each x n \u2208 \u211dd or {1, \u2026, N obs} for \ncontinuous and discrete observations, respectively). The goal of \nlearning is to recover the topology of the environment G from se -\nquences of actions and observations.\nConcretely, an environment is defined by a directed multigraph \nG \u2261 {V, E} with latent nodes V \u2261 {v 1, \u2026v Nnodes } and latent edges E \u2261 \n{e1, \u2026e Nedges }. At each time step n, the agent exists at a latent node and receives the observation x n. The node is labeled by the dis-\ncretized observation yn (when the observations are already discrete \nyn = xn). Multiple latent nodes can have the same label, so the obser -\nvation does not directly identify a node. When an agent at latent \nnode vi executes an action a, it will transition to v j with probability \nP(v j\u2223vi, a). Whenever this probability is larger than 0, an associated \ndirected edge from v i to v j is introduced in the graph, labeled with \nthe corresponding action and probability. Note that this means that \nthe graph can contain multiple edges with the same starting and \nending node, but labeled with different actions. This is what makes \nG a multidigraph and not a simple graph. For consistency, all edges \nA\nB\nDC\nFig. 1. Clone- structured cognitive graph. (A) l earning cognitive maps from sequential sensory observations is challenging because observations do not identify loca-\ntions uniquely. (B) the cognitive map learning problem can be understood as learning a latent graph from observations emitted at every node, where two different nodes \ncan emit the same observation. the challenge is to learn context- specific representations that will disambiguate sensory observations in the latent space. the observation \nD occurs in three different contexts in sequences A \u2192 D \u2192 E (purple), B \u2192 D \u2192 F (green), and C \u2192 D \u2192 G (orange) from the environment, a distinction that is not repre -\nsented in a first-  order Markov model. two of these contexts (purple and green) correspond to the same latent state, and the third (orange) to a different latent state. \ncloning D into multiple latent states allows for flexible merging and splitting of contexts as appropriate. (C) the cloning structure of dynamic Markov coding can be incor -\nporated in an hMM with a structured emission matrix, the cloned hMM. cSc G extends cloned hMMs by including actions. (D) cSc G learns an allocentric map from aliased \negocentric local observations in a 2d room with uniform interiors even with long runs of the same observation (i). (ii) each unique sensation, indexed by color, is attached \nto a set of latent states (clones) through the emission matrix. through learning of the transition matrix, these clones learn to represent different temporal contexts of that \nsensation. (iii) learned transition graph among clones. each clone\u2019s color represents the observation it is attached to. the red arrows highlight the observations corre -\nsponding to the clones in the top- left corner of the graph. (iv) clone activations as the agent navigates the room can be used to compute their place fields, which reveal \nthe spatial locations they represent.\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n3 of 16originating from the same node and labeled with the same action \nmust have their probabilities sum up to 1.\nThe above definitions result in a precise, action- conditional proba-\nbilistic model for sequences. Using z n to represent the unobserved \nnode at time step n , and adding a simple per- node policy P (an\u2223zn) to \nalso model the actions, results in the CSCG model. To extend CSCG \nto continuous observations, we introduced a variable y n between the \nhidden state z n and the observation x n. The joint distribution of a se-\nquence of observations and actions is\ndepicted as a probabilistic graphical model in Fig.\u00a01C. We use the \nfollowing shorthand for a sequence of actions: a \u2261 {a 1\u2026, aN} (x, y, z \nare similarly defined). The transition probabilities are fully parame-\nterized through an action- conditional transition tensor T with ele -\nments Tijk = P(z n+1 = k\u2223zn = j, an = i). In this formulation, the \nobservation model p(x n\u2223yn) = \ud835\udca9(x n\u2223\u03bcyn, \u03c32I) is parameterized as an \nisotropic Gaussian with variance \u03c32 and mean \u03bc yn, which is the cen-\ntroid associated to the discrete emission yn. The emission model is \nparameterized by an emission matrix E  with elements E ij = P(yn = \nj\u2223zn = i). When there are only a finite number of observations or the \nobservations are actually discrete, the observation model becomes \ndeterministic and we can set y n = xn. This exactly recovers the dis-\ncrete CSCG from (15).\nIn a CSCG, by design, multiple hidden states share the same \nemission: If states i  and j  are clones of the same emission, then p (y\u2223z = \ni) = p(y\u2223z = j). We define C(y) as the set of clones of the emission y. \nFurther, in a CSCG, the emissions are deterministic, p(y\u2223z = i) = 1 if \ni \u2208 C(y) and 0 otherwise. Simply put, each hidden state maps to only \na single emission. This clone stucture can be used to further simplify \nthe joint distribution\nObserve that if we remove the policy P(an \u2223 zn) from Eq.\u00a02, we are \nleft with the conditional model p (x \u2223 a). This action- conditional set-\nting corresponds to an (action- conditional) hidden Markov model \n(HMM) in which the emission matrix is fixed and determined by the \ncloning structure, which improves the model\u2019s learnability (15,  18). \nThe clone structure introduces a sparsity pattern in the emission ma-\ntrix, which is computationally advantageous for both learning and \ninference ( 15). In addition, the model supports causal semantics (19) \nand learning from interventions (20,  21). A CSCG\u2019s learned transi-\ntion tensor can be represented by a directed multi- graph, and reus-\ning this learned transition structure along with the cloning structure \nto remap to a new environment can be considered as learning using \nsoft interventions ( 21).\nFor a given sequence of actions, the learned transition tensor \nP(zn+1\u2223zn, an) encodes a distribution over sequences, establishing a \nconnection between observed temporal sequences and arbitrary hid -\nden (not necessarily Euclidean) topologies G  of the environment. CSCG achieves this by having an overcomplete latent space where \nthe latent states vastly outnumber the visible discrete observations, \nwith the hidden states partitioned into disjoint sets, each set corre-\nsponding to a visible observation, and the members of each set be-\ning the clones of the corresponding visible observation. This kind of \nlatent structure gives the flexibility to split the same observation in \ndifferent sequential contexts or merge different temporal contexts \ninto the same latent state (12), as shown in Fig.\u00a01, while mitigating \nthe local minima problem associated with learning latent space \nmodels ( 15).\nLearning the latent topology represented by P(zn+1\u2223zn, an) is \nachieved using expectation maximization (EM), which maximizes \nthe likelihood of the model using a local update mechanism. The \ntensor P(zn+1\u2223zn, an) is initialized randomly, and the number of la-\ntent states allocated is the \u201ccapacity\u201d of the model. Typically, the \nmodel is allocated excess capacity than what is needed to represent \nthe environment, and the learning algorithm can use this capacity to \nrepresent the splits and merges (Fig.\u00a01B) in the latent space to mod-\nel the observed sequences. Such overparameterization also helps \nwith better learning by avoiding local minima traps. The random \ninitialization can be thought of as a superposition of all possible la-\ntent graphs, and maximum likelihood learning as a smooth param-\neterization of the topology learning problem. The splitting and \nmerging of latent states that is conceptually shown in Fig.\u00a01B is \nachieved by the re- weighting of the connections by the EM updates \nwithout a change in the number of neurons. Updates using the EM \nalgorithm smoothly pushes a randomly initialized P (zn+1\u2223zn, an) \ntoward a superposition of multiple copies of the true graph G of the \nenvironment. This superposition can be further consolidated by \nrunning a greedy version of EM, called the Viterbi EM, which col-\nlapses the superpositions into a sparse tensor, pruning the connec-\ntions of unnecessary clones. (See the Supplementary Materials for \nmore details.)\nOur work focuses on the computational and algorithmic aspects \nof sequence learning in the brain and not on the actual implementa-\ntion in neuronal networks. However, we do believe that inference \nand learning in CSCG can be achieved using biologically plausible \nmechanisms ( 15, 22). The clones in a CSCG may be represented by \nan assembly of neurons. Message- passing inference in CSCG is com-\nputationally cheap and biologically plausible using simple integrate-  \nand- fire neurons (23). The EM algorithm that is used for learning is \na local update mechanism analogous to spike timing\u2013dependent \nplasticity (24,  25). See (15) for a circuit representing a potential bio-\nlogical implementation of the inference updates in CSCG.\nRESUL TS\nWe tested the CSCG model in a variety of experimental settings. The \nfirst set of experiments investigated the ability of a CSCG to learn \nlatent topologies from perceptually aliased observation sequences, \nthe ability to represent maps of multiple environments in the same \nmodel, and the ability to transitively stitch global maps from tempo-\nrally disjoint but spatially overlapping experiences. Furthermore, we \ninvestigated the ability of the model to use previously acquired \nstructural knowledge to guide behavior in unfamiliar environments. \nAll these properties are important for the performance of an animal. \nThe second set of experiments investigated CSCG\u2019s ability to repro-\nduce and explain a broad set of well- known experimental phenom-\nena from the hippocampus (see Table\u00a01). These phenomena can be p(x,a)=/uni2211.s1\nz/uni2211.s1\nyP(z1)N\u22121/uni220F.s1\nn=1P(zn+1\u2223zn,an)\nP(an\u2223zn)N/uni220F.s1\nn=1p(xn\u2223yn)P(yn\u2223zn)(1)\np(x,a)=/uni2211.s1\nz1\u2208C (y1)\u22ef/uni2211.s1\nzN\u2208C (yN)/uni2211.s1\nyP(z1)N\u22121/uni220F.s1\nn=1\nP(zn+1\u2223zn,an)P(an\u2223zn)N/uni220F.s1\nn=1p(xn\u2223yn)(2)\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n4 of 16broadly divided into spatial, geometry- related, and landmark-  related re -\nmapping (3 , 26\u201328), phenomena with both spatial and temporal com -\nponents (8 , 27), and place field repetition, distortion, and changes with \nrespect to environmental connectivity (29\u201331). In addition, we per -\nformed a set of experiments that serve as testable predictions for CSCG\u2019s \nability to explain the mechanisms underlying hippocampal phenomena.\nCSCG can construct maps from aliased egocentric \nobservations in diverse environments\nCSCGs are successful in learning latent topologies in a variety of \nenvironments, including two- dimensional (2D) and 3D simulated \nenvironments (Figs.\u00a01D and 2A), from purely sequential aliased ran-\ndom walk observations. In the uniform room example in Fig.\u00a01D, \nthe agent received egocentric visual observations quantized though \na vector quantizer, and took egocentric actions, with four possible \nheading directions in each location. The visible input to the agent \ndepended on its location as well as head direction. Learning in CSCG \ndiscovered the latent headings and locations and represented them us-\ning separate clones (Fig.\u00a01Diii). Each node in the graph (Fig.\u00a01Diii) \ncorresponds to a clone, and its color represents the local observation it \nis attached to. Note that the learning of the transition graph discovered \nfour clones per spatial location; this corresponds to the four possible \nheadings that an agent can be in (see the Supplementary Materials for \nmore details). CSCGs are also able to correctly learn the topology of \nmore complicated simulated 3D environments from sequential aliased \negocentric observations as illustrated in Fig.\u00a02A.\nWhile each clone in the transition graph in Fig.\u00a01Diii is \u201cbottom- \nup\u201d responding to the local sensation indicated by the color, that \nsensation needs to occur in the latent sequential context specified by \nthe transition graph. By representing sequential contexts in the la-\ntent space, these clones come to represent variables like locations \nand heading that are not directly sensed. An experimenter can ob-\ntain the place field of a clone by creating a map representing the \narena that the agent is moving in, and marking and accumulating \nthe instantaneous activities of the clone at the present ground- truth \nlocation of the agent on that map. Examples of such place fields are \nshown in Fig.\u00a01Div. The clones in Fig.\u00a01Diii are also head direction \nsensitive, which corresponds well with the observation in (32) that place fields show head direction sensitivity when they are mapped \nconditioned on head direction. See fig.\u00a0 S9 for examples of place \nfields and their head direction sensitivity, consistent with contem-\nporary observations about view sensitivity of place fields (32\u201335). \nWhile the place field can give rise to the interpretation that the clone \nis responding to that particular location, this is purely an interpre-\ntive convenience for the experimenter. The agent itself has no mech-\nanism by which it can derive a place field from the activity of its \nneurons. As we show in the next section, the agent does not need to \ncompute place fields to locate itself, nor need to decode locations \nfrom the clones to make navigation decisions.\nCSCGs make complex latent transitive inferences during learning \nand represent the learned information to enable transitive inferences \n(36). When different overlapping sections of an environment are ex-\nposed to the agent in disjoint episodes, CSCGs learn the underlying \nmap that stitches together the whole environment (Fig.\u00a02B), including \nthe global loop closures. When environments are really disjoint, CSC-\nGs learn to separate the maps, and simultaneously represent multiple \nmaps in memory without being explicitly instructed about map bound-\naries during training (Fig.\u00a02C). The appropriate map can then be re-\ncalled as hidden state inference ( 37) and used to guide behavior.\nReplay- based planning and schema- based transfer enable \nshortcut inference in dynamic settings\nA behaving agent can keep track of its state as the most likely clone \ngiven past observations, without having to invoke any concepts \nabout space or place fields. If the agent intends to navigate to a previ-\nously remembered goal based on a visual sensation, the action se-\nquences that achieve this can be directly inferred from the latent \ngraph. By re- activating the remembered clone corresponding to the \npreviously encountered visual sensation, and propagating messages \nforward and backward from the clone corresponding to the current \nlocation, the agent can infer an action sequence from the current \nstate to the target. Such message passing\u2013based planning in CSCGs \ninvolves forward and backward sweeps from the current state, and \nis akin to replays in the hippocampus (38,  39). See (15) for a visu-\nalization of the replay dynamics in CSCG. While recurrent neural \nnetworks or transformers have the representational power, and Table 1. List of experiments, their observed phenomena, and related publications. \nExperiment Phenomena Publications\nGeometry changes Place field remaps as determined by geometry O\u2019Keefe and Burgess (27)\nvisual cue rotation Place field rotates with cue card Muller and Kubie (26)\nBarrier addition Place field disruption near barrier Muller and Kubie (26)\nlandmark vector cells Place field remaps w.r.t. a landmark deshmukh and Knierim (3)\nlinear track Place field remaps w.r.t. start and end of the track Sheehan et al. (28)\ndirectional place fields Place field remapping is sensitive to movement \ndirectionO\u2019Keefe and Burgess (27)\nlaps on a track event- specific rate remapping and lap cells Sun et al. (8)\nFour connected rooms Place fields are unaffected by closed doors duvelle et al. (31)\ntwo identical rooms Place fields are repeated in two identical rooms Fuhs et al. (29)\nhairpin maze direction- specific repetition of place fields derdikman et al. (30)\nRoom size expansion Place fields expand or stretch based on location \nw.r.t. boundariestanni et al. (43)\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n5 of 16could arguably be trained to predict the next observation as well as \nCSCGs, their latent space is not structured like a graph. A striking \nadvantage of CSCG in comparison to such models is that learned \nmaps can be quickly reconfigured to reflect changes in the environ-\nment. When a previously passable route is blocked, the corre-\nsponding structural modification can be made in the latent graph, \nand message passing\u2013based inference will use this updated infor -\nmation about the environment to navigate around obstacles (15).\nCSCGs can also transfer prior knowledge to new environments \nand infer shortcut paths through unobserved locations by treating \nthe learned transition graph as a schema (40\u201342) and learning just \nthe emission matrix. To demonstrate this ability, we first trained a \nCSCG using aliased observations from random walks in an environ-\nment composed of four connected 3D rooms. Next, we placed the \nagent in an unfamiliar room with the same structure (test environ-\nment in Fig.\u00a02D), but with variations in wall colors and lighting con-\nditions. As the agent walks in the new room, we keep the transition \nmatrix of the CSCG fixed and update the emission matrix with the \nEM algorithm. Just from the partial experience of walking through \nthree of the four rooms, the CSCG is able to infer the shortest path to the start location through the previously unvisited room. Notably, \nthe environment is not a 2D plane amenable to Euclidean vector nav-\nigation: The inferred shortest path involved an elevated platform ac-\ncessed via a ramp as shown in Fig.\u00a02D, where the agent had to first \nnavigate away from the goal (in a Euclidean sense) to access the ramp. \nEven with partial knowledge of an environment, an agent can vicari-\nously evaluate the sequence of actions to be taken to reach a destina-\ntion by reusing the CSCG\u2019s transition graph from a similar, previously \nexperienced environment. This experiment shows the potential of \nCSCG to use its learned structures as schemas, and it required the \nexperimenter\u2019s intervention to update only the emission matrix while \nkeeping the transition matrix fixed. It shows the path toward a more \ngeneral model that could be automatically and simultaneously updat-\ning multiple emission matrices and transition matrices, and dynami-\ncally choosing which of these models to use for behavior.\nRemapping due to changes in overall geometry, visual cues, \nor landmarks can be explained using sequence learning\nChanging the interpretation of place fields from explicitly represent-\ning spatial locations to representing the sequential context in which \nA\nBC\nD\nFig. 2. CSCGs learn diverse latent topologies, transitively stitch them, and transfer structure to new environments. (A) cSc G learning in an example 3d environ-\nment. the agent navigates the environment with egocentric actions and gets observations as RGB images. the images are passed through a vector quantizer to obtain \ncluster indices, which are used as observations for training a cSc G. the learned transition graph reflects the topology of the environment, which is a square room with a \nplus- shaped barrier in the center. (B) An agent experiences an environment composed of four connected 3d rooms in disjoint sequential episodes. each episode has only \npartial coverage of the locations in the composite room. cSc G learning stitches together the disjoint experiences into a coherent global map. (C) An agent experiences \nmultiple sequential episodes sampled from four nonoverlapping 3d rooms. i n this case, cSc G learning correctly learns separate maps for each maze. (D) t he learned \ntransition graph of a cSc G trained on one environment can be considered a reusable schema. Given partial experience in an unfamiliar environment, a differently colored \nvariation of the four- room environment used in (B), the previously learned joint transition model can be used to identify the agent\u2019s location within it and rapidly navigate \naround obstacles to find the shortest path to the goal (here, to return to the starting location).\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n6 of 16a sensation occurs explains a wide variety of place cell remapping \nphenomena. In the transition graph in Fig.\u00a01Diii, each state should \nbe interpreted, not as responding to a specific location in the room, \nbut as responding to the specific sequence of observations leading \nup to that location. As we demonstrate, sequential interpretation of \nspatial representations can explain a variety remapping driven by \nchanges in geometry, visual cues, transparent or opaque barriers, \nlandmarks, distances to start or end locations, etc.\nThe classic experiments on geometry change\u2013driven remapping \n(27) can be explained using CSCGs as follows: Changing the geom-\netry of a room changes the locations where similar sequential contexts \nwill be observed. In these experiments, place fields that developed while the rat trained in an arena remapped in a geometry- dependent \nmanner when the arena was elongated or widened. We demonstrate \nthis by first training a CSCG on a small square (SS) room (size 9 \u00d7  9) \nwith uniform interior and observing the place field changes of clones \nin test rooms that varied in size along the two dimensions (see \nFig.\u00a03A). The activations of clones in a CSCG represent the posterior \ndistribution over latent states given the past sequence of observa-\ntions. As described earlier, the specific sequential context in which \nclones activate can be interpreted as coding for location. Since the \ninteriors of a uniform room have undifferentiated local sequential \ncontext, the responses of clones in the center will be anchored with \nrespect to the boundaries because of the relative uniqueness of the \nA\nB\nDC\nE\nFig. 3. CSCG reproduces several place field remapping phenomena. (A) A cSc G was first trained in a small square (SS) room (i). (ii) Place fields were computed in the \nSS, horizontal rectangle (hR), vertical rectangle ( vR), and large square (lS) rooms. notably, clone 314 maintained a consistent place field anchored to the top- left corner, \nwhile clones 161 and 748 exhibited field splitting when the room is elongated along the horizontal and vertical axes, respectively. (iii) the cSc G also replicated direc -\ntional place fields reported in (27). (B) When trained in a circular room with a cue, the cSc G demonstrated that place fields also rotate when the cue is rotated. For most \nclones, the place fields disappear when a barrier is introduced. (C) trained in a rectangular layout with a landmark, the cSc G exhibited place fields with two components \nin the modified layout: one at the original location and another at a vector displacement from the new landmark location. (D) A cSc G was trained on a linear track using \noutbound and inbound walks. Place fields were computed using trials with different starting positions for the outbound trajectories and different end positions for the \ninbound trajectories. Most clones coded distance from the start box, while others were anchored to the end box. (E) A cSc G was trained in a rectangular maze similar to \n(8), with training trials comprising three laps followed by a reward at the end. d uring test trials, the reward was shown at the end of four laps. Place fields computed with \ntraining trials show that there are different clones that are maximally active for different laps. i n test trials, lap three clones are substantially active in both the third and \nfourth laps, reflecting the absence of a reward in the third lap.\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n7 of 16observations there. When navigating an elongated room using the \nCSCG learned from the smaller room, the internal states will reli-\nably signal end- of- room states when the agent is near the boundar -\nies of the new room. This effectively creates two loci for sequential \ncontexts. The same clone that fired in the sequential context corre-\nsponding to a specific location in the original room will now fire at \ntwo different locations due to the splitting of the sequential contexts \nin the elongated room, as reflected in the remapped responses of \nclones 161 and 748 in Fig.\u00a03A. In contrast, the response of clone 314 \ndoes not remap and remains the same in all four rooms. This is \nbecause this neuron\u2019s sensory input already includes part of the \nboundary, and also because the sequence it represents has shorter \nundifferentiated segments from the boundary, making it strongly \nanchored. Although these results were originally characterized as \nboundary vector coding, our results show that the major findings of \n(27) can be explained using sequence representation without using \ngeometric concepts. As we describe later, the sequence perspective \nalso naturally explains the temporal dependence of the remapped \nplace fields. Note that remapping relies on changes in the environ-\nment being superposed on a previously learned graph without any \nnew learning. Of course, with further training in the new environ-\nment, the remapping will diminish because new place fields repre-\nsenting the new environment will develop with more experience in \nthat environment.\nThe classic Muller and Kubie experiments (26) showing a variety \nof remapping phenomena can also be explained using CSCG, which \nwe illustrate in Fig.\u00a03B. In these experiments, rats were trained in a \ncircular arena with a cue card placed on the wall. Researchers found \na variety of remapping phenomena with respect to rotation of the \ncue card and introduction of opaque or transparent barriers. To in-\nvestigate these phenomena, we first trained a CSCG in a circular \narena with a cue card at the 12 o\u2019 clock position. In this environment, \nthe differentiated sequential contexts will develop with reference to \nthe cue card. When we computed place fields with this CSCG in \nan arena where the cue was rotated, the place fields also rotated \naccordingly because they are always referenced to the context and \nnot the absolute location. Placing a barrier in the arena has two ef-\nfects that destroy the place field for some clones. One effect is that \nthe barrier prevents the agent from taking some trajectories that are \nimportant for revealing the relevant sequential contexts for some \nclones. The second is that the presence of the barrier can change the \nvisual sensation in its vicinity. Both these effects combine to explain \nwhy place fields are disrupted when a barrier is placed through its \ncenter, and not affected when the barrier is far away.\nCSCGs also explain why place cells can be seen as encoding a vec-\ntor relationship to local landmarks (3 ). Just like cue cards, or boundar -\nies, landmark objects placed in an environment act as disambiguating \ncontexts with respect to which sensations at other locations are en-\ncoded. Thus, when a landmark is moved, some of sequential contexts \nalso move in reference to that landmark. We illustrate this landmark \nvector remapping phenomenon in Fig.\u00a03C. We first trained a CSCG in \na rectangular layout with a landmark on one side of the room. We \ncomputed place fields in this layout as well as a modified version in \nwhich the landmark was moved to a different location. In the modi-\nfied layout, the place fields now have two components\u2014one at the \nsame location as in the original layout, and the second at the same \nrelative displacement from the new location of the landmark.\nIn more recent experiments (28), rats were trained on outbound \nand inbound traversals on a linear track that could be changed in length. Responses to the appropriate sequential contexts in a CSCG \nnaturally explain the remapping of place fields observed as the track \nlength varies. To demonstrate this, we first trained a CSCG on a linear \ntrack of length 18 steps using both outbound (left to right) and in-\nbound (right to left) walks. We then computed place fields separately \non outbound and inbound trajectories for various track lengths \n(Fig.\u00a03D). We observed that most clones coded for distance from the \nstarting position. The place fields gradually widened with distance \nfrom the starting position reflecting the growing uncertainty in the \ndistance from the starting point. There were also clones anchored to \nthe end point of the trajectories.\nSequence representation can explain puzzling phenomena \nthat mix spatial and temporal effects\nSequential contexts naturally explain the direction sensitivity of \nplace field remapping reported in (27). When the room is elongated, \nsome place fields that were unimodal in the original room remapped \nto produce two peaks, corresponding to two subcomponents in the \nelongated room. It was observed that these peaks were direction \nsensitive: The left subcomponent was active during rightward travel \nand vice versa. We tested CSCG for the same effects using the same \nsettings as in Fig.\u00a03A, by plotting the fields conditioned on the direc-\ntion of travel. In the horizontal rectangle room, rightward and left-\nward trajectories of the agent strongly activated the left and right \npeaks of the place field, respectively, as shown in Fig.\u00a03Aiii. This is \nbecause only one of the sequential contexts that activate a clone oc-\ncurs in a directional walk, which is a natural consequence of repre-\nsenting locations using sequential contexts. In contrast, a purely \ngeometric model like the boundary vector model (41) does not offer \nan explanation for the direction sensitivity of place field remapping.\nCSCG can also explain recently discovered phenomena like \nevent- specific rate remapping (ESR) cells (8), which signal a combi-\nnation of location and lap number for different laps around a maze, \nwithout postulating special coding mechanisms. Figure\u00a03E shows a \nsimilar setting to an experiment in (8) where a rat runs multiple laps \nin a looping rectangular track before receiving a reward. We trained \na CSCG on trials comprising three laps of a rectangular track with a \nreward state at the end of the third lap. A CSCG exposed to the se-\nquence of observations from such trials learned to distinguish the \nlaps and to predict the reward at the end of the third lap, without the \nhelp of any explicit lap- boundary markers in the training sequence. \nThis is reflected in the place fields of the clones for the training trials \n(left panel in Fig.\u00a03E)\u2014each clone is maximally active for an obser -\nvation when it occurs in its specific lap. However, each clone also \nshows weak activations when its corresponding observation is en-\ncountered in other laps, a signature of ESR. This occurs naturally in \nthe CSCG due to probability smoothing and the inference dynam-\nics. CSCGs can also explain the remapping of ESR cells. We com-\nputed place fields on test trials comprising four laps, instead of three, \nin which the reward was at the end of the fourth lap. The lap three \nclones were strongly activated in both the third and the fourth laps, \nreflecting the change when the reward state is reached (right panel \nin Fig.\u00a03E).\nCSCG can predict what kinds of environmental changes lead \nto remapping\nCSCGs show that environmental connectivity changes need not \nlead to place field remapping even when the agents\u2019 behavior shows \nadaptation to the change, a phenomenon that researchers found \nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n8 of 16puzzling. In (31), rats ran in a four- room maze where the doors con-\nnecting the rooms could be selectively locked to change the connec-\ntivity of the arena. The rat\u2019s behavior reflected that it recognized the \nconnectivity changes of the environment, but the place fields did not \nremap in response to these connectivity changes. The authors found \nthis lack of remapping puzzling and argued that place cells do not \nencode a topological map. However, CSCGs show that place cells \ncan encode global location in their activations, global topology in \nthe cell- to- cell connectivity, and still not show remapping in re-\nsponse to the manipulations in (31).\nTo demonstrate this, we trained a CSCG using a random walk in \nan environment comprising four square rooms that are connected \nby two- way doors, similar to the experimental setting in (31). Each \nroom had visual cues that distinguished it from the other rooms. \nCSCG learned the global topology of the arena in the transition ma-\ntrix, and the activation of clones corresponded to locations, as in \nprevious experiments (Fig.\u00a04A, top row). We then tested for two en-\nvironmental modifications used in (31): (i) One door was locked \nboth ways effectively creating a blockade, and (ii) all doors were \nlocked in one way allowing only an anti- clockwise direction of tra-\nversal in the environment. The corresponding modifications were \nmade in the CSCG transition matrix by modifying the connections \nappropriately, and planning routes in this modified CSCG corre-\nsponded to the reported successful navigation. We then computed \nplace fields using the appropriately modified CSCGs paired with the \narena connectivity changes, and compared these to the fields from \nthe original CSCG in the original arena. In Fig.\u00a04A, we show that the \nplace fields were the same across all three settings, consistent with \nthe observations in (31).\nThe reason for lack of remapping can be understood by realizing \nthat the connectivity change blocked paths without any change in \nthe visual cues. The blocked path affected only a few of the potential \nsequences that were responsible for that place field, a change that is \ntoo small to be reflected in the aggregated sequential responses. \nHowever, the connectivity change can still lead to large changes in \nbehavior, for example, in navigation between the two rooms. In \nCSCGs, those changes will be reflected in the replay messages used \nfor planning and in the computed shortest paths.\nWhile the explicit latent graph representation of CSCG allows for \nrapid structural modification of the internal model of an agent in \nresponse to environmental changes, the changes itself were manu-\nally made by the experimenter in the current results. Making these \nmodifications automatically and dynamically in response to sur -\nprise would result in a further integrated model and is an area of \nfurther research.\nSequence learning explains place field repetition, size, and \nshape variations\nPlace fields distort along the boundaries and increase in size system-\natically toward the center of an empty arena (43). In very elongated \nrooms, place fields have multiple lobes. In some settings, place fields \nare known to repeat in identical rooms (29, 44). While all these phe-\nnomena appear to be spatial, CSCGs provide cogent explanations \nfor these in terms of sequence learning: All of them result from state \naliasing due to the difficulty in creating different latent states for \ntemporal contexts that are identical for long number of steps.\nTo demonstrate place field repetition in visually identical environ-\nments, we trained a CSCG in a layout comprising two visually identi-\ncal rooms in the same orientation and connected by a corridor, as shown in Fig.\u00a04B, similar to the setting in (29). Place fields computed \nin this layout show repetition, i.e., clones are active at the same loca-\ntion in both rooms. We also considered a layout in which the two \nrooms were abutted by rotating them such that their orientations dif-\nfered by 180. In (29), it was reported that place field repetition disap-\npears in the different orientation setting. This was attributed to the \nrats potentially being able to maintain their inertial angular orienta-\ntion. With CSCGs, in the absence of an external \u201ccompass, \u201d we ob-\nserve that place field repetition persists in the modified layout, even \nafter the introduction of an asymmetric connection between the two \nrooms. However, when the CSCG was retrained on the different ori-\nentation setting with an asymmetric connection between the rooms, \nit was able to partially split contexts in the two rooms. This resulted \nin unique place fields for most clones, as shown in Fig.\u00a0 4C. If the \nsensory input to CSCG is augmented with an external head direction \ninput, then the different orientation setting results in unique place \nfields in CSCGs, similar to what is observed in (29).\nIn Fig.\u00a04D, we reproduce the direction- dependent place field rep-\netition reported in (31). We trained a CSCG on a hairpin maze, with \ndistinct end markers and a cue to distinguish top and bottom walls, \nusing left to right (L \u2192 R) and right to left (R \u2192 L) walks. Place fields \ncomputed using this CSCG using only L \u2192 R or R \u2192 L walks reveal \ndirection- dependent place field repetition, as shown in Fig.\u00a04D. For \nexample, clone 42 is activated at the same location in multiple seg-\nments of the maze, but only in the L \u2192 R traversal. The top and \nbottom walls of the maze have different observations, which pro-\nvides the CSCG enough context to disambiguate the two directions \nof travel. However, for each direction of traversal, the observations \nare the same in all segments of the maze, except the ends, resulting \nin the repetition of place fields.\nTo study the effect of room size on place fields (43), we trained \nthree different CSCGs on square rooms, with uniform interiors, of \nside length 7, 9, and 11, respectively. As an agent moves away from \nthe boundaries to the center of an empty room, different sequential \ntrajectories start to look the same, making it difficult for the learning \nalgorithm to split the contexts into different clones. This results in \nthe same clone representing more contexts than it would in the pe-\nriphery of the room where contexts can be easily distinguished. In \nplace field mapping, this will appear as an enlargement of the place \nfields in the center of the room (\u201cCenter\u201d column in Fig.\u00a04E). Simi-\nlarly, the observations along the edge of a room might not all devel-\nop into distinct clones, resulting in multiple observations along the \nedge being aliased into the same clone. This aliasing, due to the elon-\ngation of the same evidence, will appear as an elongation of the place \nfield (\u201cEdge\u201d column in Fig.\u00a04E).\nPlace field size expansion (43) in an empty arena happens be-\ncause of the same reason as place field repetition in two identical \niso- oriented rooms. Both can be explained by the inability of the \nmodel to split very long- term temporal contexts into distinct latent \nclones with the given amount of training. (Of course, longer training \nwill partially overcome this problem, which is observed in animals \nas well.) In that sense, larger place fields are the same as place field \nrepetition, just happening in adjacent locations.\nTestable predictions made by CSCGs\nCSCGs can also make experimentally testable predictions for yet to \nbe observed phenomena. One such prediction is the following. What \ncontrols how place fields change is not the rate of visual change, but \nthe uniqueness of the visual context. To demonstrate this, we trained \nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n9 of 16two CSCGs on square rooms with checkerboard and random patterns \non the floor, respectively. We observed that the place fields in the \ncheckerboard room were more expanded, as shown in Fig.\u00a04F. This is \nbecause the same context repeats throughout the interior of the \nroom, making it difficult for the learning to split the contexts into \ndifferent clones.\nCSCGs provide a mechanistic explanation for the question of \nwhen and why do place fields globally or partially remap. The answer: Place cell responses are driven by their sequential contexts, and \nchanges that substantially affect the sequential context of a neuron are \nwhat determines when and how its field will remap. In the abstract, \nsequential context for a sensory observation can be thought of as the \nhistory of sensory observations that can predict it. The CSCG model \nmakes this abstract definition concrete and measurable: Sequential \ncontext for a latent state is the temporal trajectories of latent states \nthat lead to it. Any change that makes the same sequential context \nAB\nC\nDE\nF G\nFig. 4. CSCG reproduces various observations about place cells such as place field repetition, size, and shape variations. (A) A cSc G trained in a layout with inter -\nconnected square rooms showed consistent place fields across settings with locked doors. (B ) A cSc G was first trained on a layout comprising two visually identical rooms \nin the same orientation connected by a corridor. Place fields were computed in a layout where the two rooms were rotated such that their orientations differed by 180. We \nalso considered a second modification, where we introduced an asymmetry in the connection between the two rooms. i n all three layouts, we observed place field repetition \nacross the two rooms, in contrast to the findings in (30), where place field repetition was observed only in the same orientation layout. (C ) however, when we retrained the \ncSc G in the layout with asymmetric connectivity, we observed that the place field repetition disappeared. (D ) cSc G reproduces direction-  dependent place field repetition \nin a hairpin maze as observed in (30). (E ) We trained cSc Gs on square rooms with uniform interiors of three different sizes. We observed that place fields at the edge and \ncenter of the room elongate and enlarge as the room size increases, while place fields anchored to a corner remain consistent across sizes. (F ) A cSc G trained on the check -\nerboard room has more expanded place fields compared to one trained on a room with a random pattern. (G ) in a room elongation experiment, we initially trained a cSc G \non a rectangular room with local landmarks on one side. Place fields were computed in both the training room and an elongated room where landmarks remained in the \nsame position. Place fields anchored to the landmarks remained consistent in both layouts, while those farther from the landmarks expanded in the elongated layout.\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n10 of 16occur in different parts of the room will result in that field partially \nappearing in the new place. The organization and specificity of local \ncontext driving the responses of a cell will have a notable impact on its \nremapping. A cell that is tuned to sequences in the middle of a uni-\nform room will have its place fields anchored by the boundaries \nthat are relatively more unique, causing the field to remap when the \nboundaries are moved. However, if the cell had some other local cues, \nfor example, markings on the floor, that would provide it a unique \nsequential context, then the cell\u2019s field will not remap when the \nboundary is moved. In Fig.\u00a04G, clone 15 and clone 128 are two cells \nfrom the CSCG trained in the training layout. When the room is elon-\ngated, the place field of clone 128 expands. This is because the local \nsequential context for clone 128 was anchored by the cyan landmark \non the left and the boundary on the right. These partial contexts occur \nin two different places in the elongated room. In contrast, the local \nsequential context for clone 15 is anchored by the blue landmark on \nits left and the cyan landmark on its right, and those did not change \nwhen the room was elongated. This means that, locally, clone 15 will \nsee the same sequential contexts after room elongation, resulting in a \nlack of remapping in its place field.\nDISCUSSION\nThe discovery of place cells is a striking success of hippocampus re-\nsearch, and place field mapping has served as a valuable tool in reveal-\ning the representational properties of neurons in the hippocampus. \nHowever, anomalies have been accumulating over the simple view \nthat place cells represent just locations (8 , 9, 32, 45, 46). Place fields \ndistort around boundaries and split along trajectories. They are direc-\ntion sensitive ( 32, 34) and can even represent the lap count in running \nloops ( 8). In some cases, insertion of a boundary in between a place \nfield clearly disrupts the place field, suggesting that fields are related to \nthe connectivity of the underlying environment (26). Y et, place fields \ncan remain unchanged when the connectivity of the environment \nchanges without any visible cues (31). If the environmental change is \nnot reflected in place fields, how are the rats able to change their be-\nhavior in the new environment? In summary, many of these questions \nabout the role of place cells\u2014what they represent, how those repre-\nsentations are learned, how they are used, and how they change with \nrespect to environmental manipulations remain unanswered in the \nlocation- centric description of hippocampal neurons. In contrast, the \nsequence- centric paradigm (45) we develop in this paper resolves \nthese anomalies by re- interpreting space as a sequence. In contrast to \nthe Kantian view of space and time as a priori, our work offers com-\nputational support for the Leibnizian view that only sequential order -\ning needs to be a priori, opening up interesting questions regarding \ninnate representations and core knowledge for cognitive science and \nartificial intelligence (AI).\nOur current work required substantial advances over the previ-\nous work that introduced the basic CSCG model (15). The previous \nwork was entirely in an allocentric setting that hardcoded action \nsemantics in a global coordinate system, which is insufficient to ad-\ndress how spatial representations emerge from egocentric actions \nand sensations. Moreover, George et al . (15) dealt only with ideal-\nized environments with discrete ordinal sensations. Additionally, \nGeorge et al. (15) did not realize how the Euclidean place field map-\nping methodology is related to the different reported phenomena. \nGeneralizing to egocentric setting and continuous high- dimensional \nsignals from visual perception in 2D and 3D environments and arbitrary topologies enabled the coverage of experiments and led to \nthe strong insights in our current work: Place is a sequence, and place \nfield mapping methodology is a source of anomalies. By improving \nthe model to learn from realistic data in complex 3D environments, \nideas in this paper have also become relevant for AI, addressing long-\nstanding questions about episodic experience, memory, cognitive \nmaps, and planning.\nWhile CSCG draws up on many past and contemporary models \nof hippocampus ( 47), it is markedly different in many aspects. In \ncontrast to temporal context models (48) that accumulate sequential \ncontext in the observation space, the sequential representation in \nCSCG is in the latent space, giving it the ability to model more com-\nplex and long- duration temporal dependencies. The ability of CSCG \nto represent locations as sequences crucially depends upon having a \nlatent representation. Although successor representations (49) can \nmodel temporal relations, they are not directly applicable in the \naliased settings we consider here. Since successor representation as-\nsumes that sensations directly correspond to locations, it cannot \nexplain how spatial representation emerges from egocentric sensa-\ntions in the partially observable settings that animals encounter in \nthe real world. The memory compression model ( 50) focuses on \ncompressing instantaneous inputs by exploiting correlations be-\ntween them. However, their experiments are in a fully observable \nenvironment where the locations can be uniquely determined di-\nrectly from the sensations, and sequence learning is not part of the \nmodel. Combined with a discretization step, this model could play \nthe role of a more sophisticated vector quantizer that can feed into a \nmodel like CSCG.\nContemporary work on Tolman- Eichenbaum machines (TEMs) \n(51) has many similarities to CSCG in inspiration. However, unlike \nCSCG, TEMs do not learn latent graphs in aliased settings like ours. \nInstead, TEMs focus on learning general transitivity rules applicable \nto a single graph from multiple noisy realizations of that graph. \nMoreover, TEMs do not deal with multiple graphs at the same time \n(52), or do latent transitive stitching. In the context of learning spa-\ntial representations, TEMs have so far been demonstrated only in \nallocentric settings with a global coordinate system, and they rely on \nthe hard- coded loop- closing semantics of allocentric actions (e.g., \nnorth- east- south- west closes the loop) to learn the representations, \nwhich does not explain how spatial representations can arise from \negocentric sensations and actions. A TEM is formulated purely as \na predictive model, and its internal representation does not learn a \nmodifiable graph that corresponds to the environment. Therefore, \na TEM does not have the same ability as a CSCG to deal with dy-\nnamic environments quickly by changing its graph connectivity or \nto form hierarchies through community detection (53) on the latent \ngraph as demonstrated in (15).\nUnlike other computational models of place fields, CSCGs do \nnot use grid fields to learn place fields and still explain varied re-\nmapping phenomena. Recent experimental evidence suggests that \ngrid cells are not necessary for learning (54, 55) and continued func-\ntioning of place cells (55). If grid cell outputs are available, CSCG \ncan use those as additional sensations. This would speed up learning \nin the middle portions of empty arenas where unique sensations are \nnot available, and it will also help stabilize the place fields away from \nthe boundaries or other landmark cues (56, 57), consistent with the \nidea of grid cells providing an optional scaffolding for place cells (58).\nAll the phenomena replicated in this work were robust without \nthe need for careful handcrafting on the side of the experimenter. \nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n11 of 16Given sufficient capacity in the number of clones, CSCG learning \nwas robust and converged to the ground- truth graph of the environ-\nment from random initializations. Only one experiment\u2014the lap \nrunning experiment\u2014required multiple random initializations to \nrecover the ground- truth graph, and we suspect that it is due to the \nextreme degeneracy of observations in the repeated laps. Moreover, \nsince all the neurons and their connections in the model are ob-\nserved, and since their representations are directly interpretable in \nrelation to the environment, the relevant neurons for analysis can be \nidentified directly by inspection rather than through sampling and \npopulation- level analysis. However, our setting can also be a good \ntest bed for studying sampling effects and population- level metrics. \nThis is left for future work. Given that the graph for an arena is \nlearned faithfully, locations can be decoded from the current most \nlikely hidden state, and this is robust despite noisy or missing obser -\nvations or actions.\nAnother under- explored property of the CSCG is its ability to \nlearn multiple maps of different fidelities and task contexts in the \nsame model, and to dynamically switch between them based on \ncontexts, just like switching between the maps of different arenas. \nThe learning dynamics of EM usually results in a latent representa-\ntion that is a superposition of multiple graphs, which we then con-\nsolidated to a single graph using Viterbi- EM. Having multiple maps \nof the same arena (59) is compatible with the CSCG representation \nand could provide explanations for more phenomena, such as the \nsimultaneous presence of unidirectional and bidirectional place \nfields in linear tracks (60). This is left for future work.\nThe most important message from our work is that many of the \ndiverse fascinating hippocampal phenomena might be artifacts of \nEuclidean place field mapping. Hippocampal cells are usually inter -\npreted by plotting their responses on to a 2D map corresponding to \nthe environment, collapsing the sequential responses into a static \nplace field. Characterizing place field maps in terms of Euclidean \nconcepts is akin to characterizing the effects rather than the under -\nlying causes and might be the source of new phenomena. Often, \nthese new phenomena are explained away invoking familiar, but \nultimately unsatisfactory, answers like distributed coding or mixed \nselectivity. These answers are unsatisfactory because instead of an-\nswering the questions they just shift the questions elsewhere. Our \nexperiments show that phenomena that look extremely different\u2014\nfor example, place field expansion in a uniform room and event-  \nspecific responses in a lap running\u2014can have the same underlying \nexplanation, which can be understood through the sequence learn-\ning model. By maintaining the same underlying model and altering \nthe environments to align with neuroscience experiments, we dem-\nonstrate how distinct phenomena emerge solely from those envi-\nronment changes through the application of the same learning and \ninference mechanisms. Rather than treating place field fidelity as \nsomething the hippocampus is trying to achieve, our examples \nserve to demonstrate why place field mapping should be treated as \njust a visualization tool that the experimenter has at their disposal. \nWe hope that this opens up a new avenue of exploration that takes \nus away from the familiar questions centered on encoding and de-\ncoding locations.\nMuch remains to be explored on this new path we have struck \nout on. To demonstrate the viability of our theory, we selected a sub-\nset of the results from each of the experiments that we judged to be \nadequately representative. However, more can be done along this \npath. For example, we did not test the model for remapping in the presence of new objects as in (3), although the model offers a poten-\ntial explanation via probabilistic inference. We have only briefly \ntouched upon replay- based planning and schemas (61), and both \ncan be expanded in future research. Place fields in animals develop \nwith considerably less experience than the amount required in our \nexperiments, and schemas could be crucial for explaining this gap \nby giving a mechanism for abstracting and transferring prior experi-\nence. Our work can also be expanded in the direction of active \nlearning and inference (62, 63). Reward mechanisms can be layered \non top of CSCG. CSCGs have the ability for temporal abstractions \nvia community detection (53) on the underlying graphs, an idea \nworthy of more exploration. Our current models are learned using \nrandom walks. Potentially efficient exploration techniques can be \ndeveloped as active learning on CSCGs. We hope that our work \ngives a concrete tool that would help hippocampal researchers think \nbeyond the place field paradigm.\nMETHODS\nExpectation- maximization learning of CSCGs\nCloned HMMs, first introduced in (14), are a sparse restriction of \novercomplete HMMs (18) that can overcome many of the training \nshortcomings of dynamic Markov coding (64). Similar to HMMs, \ncloned HMMs assume the observed data x \u2261 {x 1\u2026, xN} are gener -\nated from a hidden process z \u2261 {z 1\u2026, zN} that obeys the Markov-\nian property\nHere, P(z 1) is the initial hidden state distribution, P(z n+1\u2223zn) is \nthe transition probability from z n to z n+1, and P(x n\u2223zn) is the proba-\nbility of emitting x n from the hidden state z n.\nIn contrast to HMMs, cloned HMMs assume that each hidden \nstate maps deterministically to a single observation. Further, cloned \nHMMs allow multiple hidden states to emit the same observation. \nAll the hidden states that emit the same observation are called the \nclones of that observation.\nCSCGs build on top of cloned HMMs by augmenting the model \nwith the actions of an agent. In this section, we first review the \nexpectation- maximization learning of cloned HMMs, before de-\nscribing the learning of CSCGs for both discrete and continuous \nobservations.\nExpectation- maximization learning of cloned HMMs\nThe standard algorithm to train HMMs is the expectation- maximization \n(EM) algorithm (65), which in this context is known as the Baum- Welch \nalgorithm. The Baum- Welch algorithm uses forward and backward \nmessage passing to compute posterior marginals of the latent variables \ngiven a sequence of observations/emissions during the expectation step. \nLearning a cloned HMM using the Baum- Welch algorithm requires a \nfew simple modifications: The sparsity of the emission matrix can be \nexploited to only use small blocks of the transition matrix both in the \nexpectation (E) and maximization (M) steps.\nLearning a cloned HMM requires optimizing the vector of pri-\nor probabilities \u03c0: \u03c0k = P(z 1 = k) and the transition matrix T: Tij = \nP(z n+1 = j\u2223zn = i). To this end, we assume that the hidden states are \nindexed such that all the clones of the first emission appear first, all \nthe clones of the second emission appear next, etc. Let N obs be the P(x,z)=P(z1)N\u22121/uni220F.s1\nn=1P(zn+1\u2223zn)N/uni220F.s1\nn=1P(xn\u2223zn) (3)\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n12 of 16total number of emitted symbols. The transition matrix T  can then be \nbroken down into smaller submatrices T (u, v) indexed by emissions \nu, v \u2208 {1, \u2026, Nobs}. The submatrix T(u, v) contains the transition \nprobabilities P(zn+1\u2223zn) for z n \u2208 C(u) and z n+1 \u2208 C(v), where C (u) and \nC(v) correspond to the clones of emissions u  and v , respectively.\nThe standard Baum- Welch equations can then be expressed in a \nsimpler form in the case of cloned HMMs. The E- step recursively \ncomputes the forward and backward probabilities and then updates \nthe posterior probabilities. The M- step updates the transition matrix \nvia row normalization.\nE- step\nM- step\nwhere \u2218 and \u2298  denote the element- wise product and division, respec -\ntively (with broadcasting where needed). All vectors are M \u00d7 1 col -\numn vectors, where M is the number of clones per emission. We use \na constant number of clones per emission for simplicity here, but the \nnumber of clones can be selected independently per emission. \u03c0(x 1) \nrefers to the portion of the prior probability vector corresponding to \nthe clones of the emission x 1. Similarly, 1(x N) is an all- one vector \nwith length equal to the number of clones of emission x N. Cloned \nHMMs exploit the sparsity pattern in the emission matrix when \nperforming training updates and inference, and achieve consider -\nable computational savings when compared with HMMs.\nCSCGs: Action- augmented cloned HMMs\nCSCGs are an extension of cloned HMMs in which an action hap-\npens at every time step (conditional on the current hidden state) \nand the hidden state of the next time step depends not only on the \ncurrent hidden state but also on the current action. The joint \nprobability density function of the observations and the actions \nis given by\nand the standard cloned HMM can be recovered by integrating out \nthe actions.\nWe group the actions with the next hidden state to remove loops \nand create a chain that is amenable to exact inference (i.e., similar to a standard HMM, we can exactly compute the required posterior mar -\nginal distribution of the latent variables given a sequence of observa-\ntions). We can write the action- conditioned joint distribution as\nLearning a CSCG requires optimizing the vector of prior proba-\nbilities \u03c0: \u03c0k = P(z 1 = k) and the action- augmented transition tensor \nT: Tijk = P(z n+1 = k\u2223, zn = j, an = i). Similar to cloned HMMs, we can \nbreak the action- augmented transition tensor T  into smaller sub -\nmatrices T(u, v, w), indexed by u \u2208 {1, \u2026, N actions }, v, w \u2208 {1, \u2026, \nNobs}. The submatrix T(u, v, w) contains the transition probabilities \nP(z n+1\u2223zn, an = u) for z n \u2208 C(v), zn+1 \u2208 C(w), where C(v) and C(w) \ncorrespond to the clones of emissions v and w, respectively. All the \nprevious considerations about cloned HMMs apply to CSCGs, and \nthe EM equations for learning are also very similar:\nE- step\nM- step\nIn (15), it was observed that the convergence of EM for learning \nthe parameters of a CSCG can be improved by using a smoothing \nparameter called the pseudocount. The pseudocount is a small con-\nstant that is added to the accumulated counts statistics matrix \n[ \u2211N\nn=1\u03beuvw(n) ], which ensures that any transition under any action \nhas a nonzero probability. This ensures that the model does not have \nzero probability for any sequence of observations at test time.\nLearning the emission matrix with transitions fixed\nWith a CSCG, transfer learning between different environments can \nbe accomplished by keeping its transition probabilities T fixed and \nlearning the emissions associated to its nodes E in the new environ-\nment. Further, if we know that the new environment preserves the \nemission structure, then we can further restrict the learning of E, \nwith all the rows of E that correspond to the same observation in the \noriginal environment sharing the same parameters.\nThe EM algorithm can be used to learn the emission matrix as \nfollows. The E- step recursively computes the forward and backward \nprobabilities and then updates the posterior probabilities. The M- \nstep updates only the emission matrix.\u03b1(1)=\u03c0 (x1)\u03b1(n+1)=T(xn,xn+1)\u22a4\u03b1(n ) (4)\n\u03b2(N )=1(xN)\u03b2(n)=T(xn,xn+1)\u03b2(n+1) (5)\n\u03beuv(n)=\u03b1(n)\u25e6T(u,v)\u25e6\u03b2(n+1)\u22a4\n\u03b1(n)\u22a4T(u,v)\u03b2(n+1)(6)\n\u03b3(n)=\u03b1(n)\u25e6\u03b2(n)\n\u03b1(n)\u22a4\u03b2(n)(7)\n\u03c0(x1)=\u03b3(1) (8)\nT(u,v)=/bracketleft.s4N/uni2211.s1\nn=1\u03beuv(n)/bracketright.s4\n\u2298/bracketleft.s4Nobs/uni2211.s1\nv=1N/uni2211.s1\nn=1\u03beuv(n)/bracketright.s4\n(9)\nP(x,a)=/uni2211.s1\nz1\u2208C(x1)\u2026/uni2211.s1\nzn\u2208C(xn)P(z1)N\u22121/uni220F.s1\nn=1P(zn+1\u2223zn,an)P(an\u2223zn)(10)P(x\u2223a)=/uni2211.s1\nz1\u2208C(x1)\u2026/uni2211.s1\nzn\u2208C(xn)P(z1)N\u22121/uni220F.s1\nn=1P(zn+1\u2223zn,an) (11)\n\u03b1(1)=\u03c0 (x1)\u03b1(n+1)=T(an,xn,xn+1)\u22a4\u03b1(n ) (12)\n\u03b2(N)=1(xN)\u03b2(n)=T(an,xn,xn+1)\u03b2(n+1) (13)\n\u03beuvw(n)=\u03b1(n)\u25e6T(u,v,w)\u25e6\u03b2(n+1)\u22a4\n\u03b1(n)\u22a4T(u,v,w)\u03b2(n+1),u=an (14)\n\u03b3(n)=\u03b1(n)\u25e6\u03b2(n)\n\u03b1(n)\u22a4\u03b2(n)(15)\n\u03c0(x1)=\u03b3(1) (16)\nT(u,v,w)=N/uni2211.s1\nn=1\u03beuvw(n)\u2298Nobs/uni2211.s1\nv=1N/uni2211.s1\nn=1\u03beuvw(n) (17)\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n13 of 16E- step\nM- step\nNote that the updates here involve \u2223Z\u2223 \u00d7 1 vectors, where \u2223Z\u2223 is \nthe total number of hidden states in the model. T(a n) corresponds to \nthe transition matrix for the action a n and is of size \u2223Z\u2223 \u00d7 \u2223Z\u2223, E(x n) is \na column of the emission matrix corresponding to the emission xn, \nand 1 xn = j is an indicator function. The forward message is initial-\nized as /uni0303.s1\u03b1(1)=\u03c0\u25e6E(x1) , and the backward message is initialized as a \nvector of all 1s. The emission matrix can be initialized randomly or \nwith equal probabilities for all observations.\nWhen the clone structure is to be preserved, the \u03b3(n) term in the \nE- step is modified as follows. For each observation j \u2208 {1, \u2026, Nobs}, \nwe set the posterior probability for all clones of j to be the same\nLearning the continuous CSCG\nTo extend CSCG to continuous observations, we introduced a new \nvariable yn between the hidden state zn and the observation xn. To \nrecap, the joint distribution of a sequence of actions and continuous \nobservations is\nwhere the observation model p(x n\u2223yn) = \ud835\udca9(x n\u2223\u03bcyn, \u03c32I) is parame-\nterized as an isotropic Gaussian with variance \u03c32 and mean \u03bc yn, \nwhich is the centroid associated to the discrete emission y n. The \nemission model is parameterized by an emission matrix E with ele -\nments E ij = P(y n = j\u2223z n = i).\nIn a simple case, if we have a finite number of potential observa-\ntions, we can allocate a centroid to each of them and set \u03c32 \u2192 0. \nWhen the observations are discrete, the observation model becomes \ndeterministic and we can set y = x. This exactly recovers the discrete \nCSCG from (15).\nWhen the observation at each time step n is indeed a continuous \nvector xn (e.g., an image), we want to maximize the following log \nlikelihoodwith respect to (w.r.t.) T, where T ijk = P(z n = k\u2223zn\u22121 = j, an\u22121 = i), and \np(y n\u2223zn) is 1 for z n \u2208 C(y n) and 0 for all others.\nParameter optimization can be done via EM, where both the ex-\npectation and maximization steps are exact. Rather than learning \nboth T and \u03bc simultaneously, we find it simpler to proceed in \ntwo steps.\nIn the first step, we fix P(z 1) = Tijk = 1/ \u2223Z\u2223, where \u2223Z\u2223 is the num-\nber of states in the hidden space, and learn \u03bc only. The problem thus \nsimplifies to maximizing\nw.r.t. \u03bc. The number of clones of a given centroid /uni0302.s1\u03bck is denoted by \nnC(k) (thus, \u2211K\nk=1nC(k)=\u2223Z\u2223 ). In the last equality, we collect all the \nGaussians that are known to have the same mean (i.e., all the clones \nwith the same centroid). The computation is more efficient, since it \nno longer scales with the total number of hidden states \u2223Z\u2223, but only \nwith the number of distinct means K.\nThe astute reader will recognize Eq.\u00a025 as the log likelihood of an \nisotropic Gaussian mixture model, which can be optimized greedily \nusing K- means. The centroids /uni0302.s1\u03bck are the cluster centers, and nC(k)\n\u2223Z\u2223 \ncorresponds to the prior probabilities of each center. In other words, \nto maximize logp(x\u2223a; T = Tuniform , \u03bc) w.r.t. \u03bc, we simply need to run \nK- means on the input data x (temporal ordering becomes irrele-\nvant) and then assign a number of clones to each centroid that is \nproportional to the prior probability of that cluster. When using K- \nmeans, the value of \u03c32 does not affect the optimization of the cen-\ntroids. Once the centroids have been chosen, one can set \u03c32 based on \nthe hard assignments from K - means, where the maximum likeli-\nhood estimate is closed form and simply matches the average distor -\ntion. Directly optimizing Eq.\u00a025 w.r.t. \u03bc and \u03c32 is also possible using \nEM (and in principle, more precise) but will be more computation-\nally expensive.\nIn the second step, we keep \u03bc fixed as per the previous step and \nlearn T by maximizing Eq.\u00a024 w.r.t. T using EM. While it would be \npossible to learn \u03bc and T simultaneously in the same EM loop, we \nfind that proceeding in these two steps results in faster convergence \nwithout considerably deteriorating the quality of the found local \noptimum.\nFor learning T, we can apply here the same idea that converts EM \nfor Gaussian mixture modeling into K- means. Instead of consider -\ning all the centroids as partially responsible (66) for each sample x n, \nwe can assign all the responsibility to the dominating Gaussian. This \nis often a very precise approximation, since the dominating Gaussian \ntypically takes most of the responsibility. In turn, this means that at \u0303\u03b1(n)=/bracketleft.s1T(an\u22121)\u22a4\u03b1(n\u22121)/bracketright.s1\u25e6E(xn)p\u03b1(n)\n=\u2223Z\u2223/uni2211.s1\nk=1\u0303\u03b1k(n)\u03b1(n) =\u0303\u03b1(n)\u2215p\u03b1(n)(18)\n\u0303\u03b2(n)=T(an)/bracketleft.s1\u03b2(n+1)\u25e6E (xn+1)/bracketright.s1p\u03b2(n)\n=\u2223Z\u2223/uni2211.s1\nk=1\u0303\u03b2k(n)\u03b2(n )=\u0303\u03b2(n)\u2215p\u03b2(n)\n(19)\n\u03b3(n)=\u03b1(n)\u25e6\u03b2(n)\n\u03b1(n)\u22a4\u03b2(n)(20)\nE(j)=N/uni2211.s1\nn=11xn=j\u03b3(n)\u2298N/uni2211.s1\nn=1\u03b3(n) (21)\n\u03b3k(n)=/uni2211.s1\nl\u2208C(j)\u03b3l(n)\u2200k\u2208C(j) (22)\np(x,a)=/uni2211.s1\nz/uni2211.s1\nyP(z1)N\u22121/uni220F.s1\nn=1P(zn+1\u2223zn,an)\nP(an\u2223zn)N/uni220F.s1\nn=1p(xn\u2223yn)P(yn\u2223zn)(23)logp(x\u2223a;T,/u1D6CD)=log/uni2211.s1\nz,yP(z1)N/uni220F.s1\nn=2\nP(zn\u2223zn\u22121,an\u22121)N/uni220F.s1\nn=1p(yn\u2223zn)\ue23a (xn\u2223\u03bcyn,\u03c32I)(24)\n(25)\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n14 of 16each time step, only the clones of the centroid that is closest (in the \nEuclidean sense) can be active. With this change, the cost per learn-\ning iteration now scales as /u1D4AA(Nn2\nC)\u226a/u1D4AA(N \u2223Z\u22232) , where we have as-\nsumed a constant number of clones n C = nC(k) for all centroids for \nease of comparison. When doing this, the observations become ef-\nfectively discrete and learning T reduces to the procedure described \nfor the standard CSCG.\nPutting all together, the final learning procedure can then be \nsummarized as follows:\n1) Run K- means on the training data for a given number of cen-\ntroids K.\n2) Assign to each centroid a number of clones proportional to the \nprior probability of that centroid, as obtained by K- means.\n3) Vector- quantize the data (train and test) by assigning to each \ndata point the label of the closest centroid.\n4) Learn the action- conditional transition matrix as if this was a \ndiscrete CSCG.\nCSCG learning stages\nIn our experiments, CSCG learning is typically performed in two \nstages: (i) EM learning and (ii) Viterbi learning. We first learn the \nmodel using the EM algorithm, as described previously, by allocating \nsufficient number of clones. The EM learning stage is always followed \nby a Viterbi training stage (67). Viterbi training can be considered as \nhard- decision EM, which uses max- product message passing instead \nof sum- product. It iteratively applies (i) the Viterbi decoding algo-\nrithm to get the most likely latent state sequence, and (ii) uses that to \nre- estimate the model parameters.\nSoft EM in the first stage can result in multiple copies of the same \ngraphs being learned in an interconnected and weighted manner, \nwhereas the hard- EM (Viterbi) stage consolidates those copies. Evi-\ndence for coexistence of multiple maps representing the same en-\nvironment using shared cells has been discovered in the mouse \nhippocampus ( 59).\nComputing place fields of clones in CSCGs\nGiven a sequence of observations and actions, we define the activa-\ntion of clone i at time n in a CSCG as the following marginal poste-\nrior probability\nSince the CSCG model (with the action a n\u22121 and hidden state z n \ncollapsed in a single variable) forms a chain, inference on it using \nmessage passing is exact. The marginal posterior distribution can be \ncomputed at each time step as follows\nwhere \u03c1(n) is the unnormalized distribution, T (an) is the transi tion \nmatrix corresponding to action a n, \u2218 denotes element-  wise product, E \nis the clone- structured emission matrix, and /uni0303.s1xn is a one- hot encod-\ning of the observation x n. The unnormalized marginal distribution \nat the first time step is computed as \u03c1(1)=\u03c0\u25e6(E/uni0303.s1x1) , where \u03c0 is the \nvector of prior probabilities.\nWhile computing place fields of a CSCG in a test environment, it is \npossible that the agent might encounter previously unseen observations. To account for new observations in test environments, we use a Ham-\nming distance based emission matrix E(Ham) in Eq.\u00a027, which is con-\nstructed as follows. For clone i  that maps to observation k  in the \nclone- structured emission matrix\nwhere dHam(k, j) is the Hamming distance between observation patches \nk and j, and \u03c3 E is a factor that controls the variance of the emission \ndistribution.\nWe also consider settings where the observations are noisy or \nuncertain. In such cases, /uni0303.s1xn can be a distribution over all possible \nobservations. A concrete example is when there is uncertainty in the \nagent\u2019s position. In this case, we model the observation vector as a \nlinear combination of observations from a window centered at the \nagent\u2019s ground- truth position (r n, cn)\nwhere W is the window size, X(r n + \u0394r, cn + \u0394c) is a one- hot vector \ncorresponding to the observation at position (r n + \u0394r, cn + \u0394c), and \n\u03c3x controls the spatial uncertainty. We also normalize /uni0303.s1xn to ensure \nthat the sum of its elements is 1.\nTo compute place fields in a given environment, we first obtain ac-\ntivations of the clones from N trials random walks of the agent, each of \nlength Nlen time steps. We can then use the agent\u2019s ground- truth spa-\ntial information to compute the average activation of each clone i  at \neach spatial location in the environment, thus obtaining its place field\nwhere \u03c1(k)\ni(n) , [r(k)\nn,c(k)\nn] are the activation of clone i  and agent\u2019s \nground- truth position, respectively, at time step n in trial k, and\nis an indicator function.\nSupplementary Materials\nThis PDF file includes:\nSupplementary t ext\nFigs.\u00a0S1 to S19\nREFERENCES AND NOTES\n 1. J. l. Kubie, e . R. J. l evy, A. A. Fenton, is hippocampal remapping the physiological basis \nfor context? Hippocampus 30, 851\u2013864 (2020).\n 2. A. Bicanski, n. Burgess, neuronal vector coding in spatial cognition. Nat. Rev. Neurosci. 21, \n453\u2013470 (2020).\n 3. S. S. d eshmukh, J. J. Knierim, i nfluence of local objects on hippocampal representations: \nlandmark vectors and memory. Hippocampus 23, 253\u2013267 (2013).\n 4. A. Sarel, A. Finkelstein, l. las, n. Ulanovsky, vectorial representation of spatial goals in the \nhippocampus of bats. Science 355, 176\u2013180 (2017).\n 5. P . A. d udchenko, e . R. Wood, \u201cSplitter cells: h ippocampal place cells whose firing is \nmodulated by where the animal is going or where it has been\u201d in Space,Time and Memory \nin the Hippocampal Formation, d . derdikman, J. J. Knierim, e ds. (Springer vienna, 2014), \npp. 253\u2013272.\u03c1i(n)=P(zn=i\u2223x1,\u2026,xn,a1,\u2026,an\u22121) (26)\n\u03c1(n)=/bracketleft.s1T(an\u22121)\u22a4\u03c1(n\u22121)/bracketright.s1\u25e6(E\u0303xn);\u03c1(n)=\u03c1(n)\nNclones/uni2211.s1\ni=1\u03c1i(n)(27)E(Ham)\nij\u221dexp/braceleft.s4\n\u2212/bracketleft.s1dHam(k,j)/bracketright.s12\n2\u03c32\nE/braceright.s4\n(28)\n\u0303xn=W/uni2211.s1\n\u0394r=\u2212WW/uni2211.s1\n\u0394c=\u2212WX(rn+\u0394r,cn+\u0394c)exp/bracketleft.s3\u2212(\u0394r2+\u0394c2)\n2\u03c32\nx/bracketright.s3\n(29)\nRi(r,c)=/uni2211.s1 Ntrials\nk=1/uni2211.s1 Nlen\nn=1\u03c1(k)\ni(n)/u1D540[r(k)\nn=r,c(k)\nn=c]\n/uni2211.s1 Ntrials\nk=1/uni2211.s1 Nlen\nn=1/u1D540[r(k)\nn=r,c(k)\nn=c](30)\n/u1D540[r(k)\nn=r,c(k)\nn=c]=/braceleft.s31, if r(k)\nn=rand c(k)\nn=c\n0, otherwise(31)\nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n15 of 16 6. J. A. Ainge, M. tamosiunaite, F. Woergoetter, P . A. d udchenko, h ippocampal c A1 place \ncells encode intended destination on a maze with multiple choice points. J. Neurosci. 27, \n9769\u20139779 (2007).\n 7. J. A. Ainge, M. A. A. van der Meer, R. F. langston, e . R. Wood, exploring the role of \ncontext-  dependent hippocampal activity in spatial alternation behavior. Hippocampus \n17, 988\u20131002 (2007).\n 8. c. Sun, W. Yang, J. Martin, S. tonegawa, h ippocampal neurons represent events as \ntransferable units of experience. Nat. Neurosci. 23, 651\u2013663 (2020).\n 9. G. Buzs\u00e1ki, R. llin\u00e1s, Space and time in the brain. Science 358, 482\u2013485 (2017).\n 10. S. d. Whitehead, d . h. Ballard, l earning to perceive and act by trial and error. Mach. Learn. \n7, 45\u201383 (1991).\n 11. l. chrisman, AAAI  (citeseer, 1992), vol. 1992, pp. 183\u2013188.\n 12. Y. niv, learning task- state representations. Nat. Neurosci. 22, 1544\u20131553 (2019).\n 13. M. h. Plitt, l. M. Giocomo, experience-  dependent contextual codes in the hippocampus. \nNat. Neurosci. 24, 705\u2013714 (2021).\n 14. A. d edieu, n. Gothoskar, S. Swingle, W. l ehrach, M. l\u00e1zaro-  Gredilla, d . George, \nlearning higher-  order sequential structure with cloned hMMs. arXiv:1905.00507 [stat.\nMl] (2019).\n 15. d . George, R. v. Rikhye, n. Gothoskar, J. S. Guntupalli, A. d edieu, M. l\u00e1zaro-  Gredilla, \nclone- structured graph representations enable flexible learning and vicarious evaluation \nof cognitive maps. Nat. Commun. 12, 2392 (2021).\n 16. h. eichenbaum, h ippocampus: c ognitive processes and neural representations that \nunderlie declarative memory. Neuron 44, 109\u2013120 (2004).\n 17. W. h. Warren, non- e uclidean navigation. J. Exp. Biol. 222, jeb187971 (2019).\n 18. v . Sharan, S. M. Kakade, P . S. liang, G. valiant, \u201cl earning overcomplete hmms\u201d in Advances \nin Neural Information Processing Systems (2017), pp. 940\u2013949.\n 19. J. Pearl, Causality ( cambridge Univ. Press, ed. 2, 2013).\n 20. J. Peters, d . Janzing, B. Sch\u00f6lkopf, Elements of Causal Inference: Foundations and Learning \nAlgorithms ( the Mit Press, 2017).\n 21. d . eaton, K. Murphy, Artificial Intelligence and Statistics (PMlR, 2007), pp. 107\u2013114.\n 22. t . Parr, d . Markovic, S. J. Kiebel, K. J. Friston, neuronal message passing using mean- field, \nbethe, and marginal approximations. Sci. Rep. 9, 1889 (2019).\n 23. R. P . Rao, Bayesian computation in recurrent neural circuits. Neural Comput. 16, 1\u201338 (2004).\n 24. B. nessler, M. Pfeiffer, l. Buesing, W. Maass, Bayesian computation emerges in generic \ncortical microcircuits through spike- timing-  dependent plasticity. PLOS Comput. Biol. 9, \ne1003037 (2013).\n 25. B. nessler, M. Pfeiffer, W. Maass, Stdp enables spiking neurons to detect hidden causes of \ntheir inputs. Adv. Neural Inf. Process. Syst. 22, 1357\u20131365 (2009).\n 26. R. U. Muller, J. l. Kubie, the effects of changes in the environment on the spatial firing of \nhippocampal complex- spike cells. J. Neurosci. 7, 1951\u20131968 (1987).\n 27. J. O\u2019Keefe, n. Burgess, Geometric determinants of the place fields of hippocampal \nneurons. Nature 381, 425\u2013428 (1996).\n 28. d . J. Sheehan, S. charczynski, B. A. Fordyce, M. e . hasselmo, M. W. howard, A compressed \nrepresentation of spatial distance in the rodent hippocampus. bioRxiv 2021.02.15.431306 \n[Preprint] (2021). https://doi.org/10.1101/2021.02.15.431306.\n 29. M. c. Fuhs, S. R. vanRhoads, A. e . casale, B. Mcnaughton, d . S. touretzky, i nfluence of path \nintegration versus environmental orientation on place cell remapping between visually \nidentical environments. J. Neurophysiol. 94, 2603\u20132616 (2005).\n 30. d . derdikman, J. R. Whitlock, A. tsao, M. Fyhn, t. hafting, M.- B. Moser, e . i. Moser, \nFragmentation of grid cell maps in a multicompartment environment. Nat. Neurosci. 12, \n1325\u20131332 (2009).\n 31. \u00c9. duvelle, R. M. Grieves, A. liu, S. Jedidi-  Ayoub, J. holeniewska, A. harris, n. n yberg,  \nF. donnarumma, J. M. l efort, K. J. Jeffery, c. Summerfield, G. Pezzulo, h. J. Spiers, \nhippocampal place cells encode global location but not connectivity in a complex space. \nCurr. Biol. 31, 1221\u20131233.e9 (2021).\n 32. l. Acharya, Z. M. Aghajan, c. vuong, J. J. Moore, M. R. Mehta, c ausal influence of visual \ncues on hippocampal directional selectivity. Cell 164, 197\u2013207 (2016).\n 33. P . e. Jercog, Y. Ahmadian, c. Woodruff, R. d eb- Sen, l. F. Abbott, e . R. Kandel, heading \ndirection with respect to a reference point modulates place-  cell activity. Nat. Commun. 10, \n2333 (2019).\n 34. J. J. Moore, J. d . cushman, l. Acharya, B. Popeney, M. R. Mehta, linking hippocampal \nmultiplexed tuning, hebbian plasticity and navigation. Nature 599, 442\u2013448 (2021).\n 35. R. U. Muller, e . Bostock, J. S. taube, J. l. Kubie, On the directional firing properties of \nhippocampal place cells. J. Neurosci. 14, 7235\u20137251 (1994).\n 36. h. eichenbaum, P . d udchenko, e . Wood, M. Shapiro, h. tanila, the hippocampus, memory, \nand place cells: is it spatial memory or a memory space? Neuron 23, 209\u2013226 (1999).\n 37. h. Sanders, M. A. Wilson, S. J. Gershman, h ippocampal remapping as hidden state \ninference. eLife 9, e51140 (2020).\n 38. h. F. \u00d3lafsd\u00f3ttir, d . Bush, c. Barry, the role of hippocampal replay in memory and \nplanning. Curr. Biol. 28, R37\u2013R50 (2018).\n 39. S. P . Jadhav, c. Kemere, P . W. German, l. M. Frank, Awake hippocampal sharp-  wave ripples \nsupport spatial memory. Science 336, 1454\u20131458 (2012). 40. P . Baraduc, J.- R. d uhamel, S. Wirth, Schema cells in the macaque hippocampus. Science \n363, 635\u2013639 (2019).\n 41. c. Barry, c. l ever, R. hayman, t. hartley, S. Burton, J. O\u2019Keefe, K. Jeffery, n. Burgess, the \nboundary vector cell model of place cell firing and spatial memory. Rev. Neurosci. 17, \n71\u201397 (2006).\n 42. W. tang, J. d . Shin, S. P . Jadhav, Geometric transformation of cognitive maps  \nfor generalization across hippocampal- prefrontal circuits. Cell Rep. 42, 112246  \n(2023).\n 43. S. tanni, W. d e cothi, c. Barry, State transitions in the statistically stable place cell \npopulation correspond to rate of perceptual change. Curr. Biol. 32, 3505\u20133514.e7 \n(2022).\n 44. W. e . Skaggs, B. l. Mcnaughton, Spatial firing properties of hippocampal ca1 \npopulations in an environment containing two visually identical regions. J. Neurosci. 18, \n8455\u20138466 (1998).\n 45. G. Buzs\u00e1ki, d . tingley, Space and time: the hippocampus as a sequence generator. Trends \nCogn. Sci. 22, 853\u2013869 (2018).\n 46. c. Ranganath, l.-  t. hsieh, the hippocampus: A special place for time. Ann. N. Y . Acad. Sci. \n1369, 93\u2013110 (2016).\n 47. B. Uria, B. i barz, A. Banino, v. Zambaldi, d . Kumaran, d . hassabis, c. Barry, c. Blundell, A \nmodel of egocentric to allocentric understanding in mammalian brains. bioRxiv \n2020.11.11.378141 [Preprint] (2022). https://doi.org/10.1101/2020.11.11.378141.\n 48. M. W. howard, M. J. Kahana, A distributed representation of temporal context. J. Math. \nPsychol. 46, 269\u2013299 (2002).\n 49. K. l. Stachenfeld, M. M. Botvinick, S. J. Gershman, the hippocampus as a predictive map. \nNat. Neurosci. 20, 1643\u20131653 (2017).\n 50. M. K. Benna, S. Fusi, Place cells may simply be memory cells: Memory compression leads \nto spatial tuning and history dependence. Proc. Natl. Acad. Sci. U.S.A. 118, e2018422118 \n(2021).\n 51. J. Whittington, t. Muller, S. Mark, c. Barry, t. Behrens, Generalisation of structural \nknowledge in the hippocampal-  entorhinal system. Adv. Neural Inf. Process. Syst. 31, \n(2018).\n 52. h. Sanders, M. Wilson, M. Klukas, S. Sharma, i. Fiete, efficient inference in structured \nspaces. Cell 183, 1147\u20131148 (2020).\n 53. A. c. Schapiro, n. B. turk- Browne, K. A. norman, M. M. Botvinick, Statistical learning \nof temporal community structure in the hippocampus. Hippocampus 26, 3\u20138 \n(2016).\n 54. h. M. tan, t. J. Wills, F. c acucci, the development of spatial and memory circuits in the rat. \nWiley Interdiscip. Rev. Cogn. Sci. 8, e1424 (2017).\n 55. M. P . Brandon, J. Koenig, J. K. l eutgeb, S. l eutgeb, new and distinct hippocampal place \ncodes are generated in a new environment during septal inactivation. Neuron 82, \n789\u2013796 (2014).\n 56. c. S. Mallory, K. hardcastle, J. S. Bant, l. M. Giocomo, Grid scale drives the scale and \nlong- term stability of place maps. Nat. Neurosci. 21, 270\u2013282 (2018).\n 57. l. Muessig, J. hauser, t. J. Wills, F. c acucci, A developmental switch in place cell accuracy \ncoincides with grid cell maturation. Neuron 86, 1167\u20131173 (2015).\n 58. d . Mulders, M. Y. Yim, J. S. l ee, A. K. l ee, t. taillefumier, i. R. Fiete, A structured scaffold \nunderlies activity in the hippocampus. bioRxiv 2021.11.20.469406 [Preprint] (2016). \nhttps://doi.org/10.1101/2021.11.20.469406.\n 59. l. Sheintuch, n. Geva, h. Baumer, Y. Rechavi, A. Rubin, Y. Ziv, Multiple maps of the same \nspatial context can stably coexist in the mouse hippocampus. Curr. Biol. 30, 1467\u20131476.e6 \n(2020).\n 60. F. P . Battaglia, G. R. Sutherland, B. l. Mcnaughton, l ocal sensory cues and place cell \ndirectionality: Additional evidence of prospective coding in the hippocampus. J. \nNeurosci. 24, 4541\u20134550 (2004).\n 61. d . Farzanfar, h. J. Spiers, M. Moscovitch, R. S. Rosenbaum, From cognitive maps to spatial \nschemas. Nat. Rev. Neurosci. 24, 63\u201379 (2023).\n 62. G. Pezzulo, e . cartoni, F. Rigoli, l. Pio- l opez, K. Friston, Active inference, epistemic value, \nand vicarious trial and error. Learn. Mem. 23, 322\u2013338 (2016).\n 63. R. Kaplan, K. J. Friston, Planning and navigation as active inference. Biol. Cybern. 112, \n323\u2013343 (2018).\n 64. G. v. cormack, R. n. S. horspool, data compression using dynamic Markov modelling. \nComput. J. 30, 541\u2013550 (1987).\n 65. c. J. Wu, On the convergence properties of the em algorithm. Ann. Stat. 11, 95\u2013103 \n(1983).\n 66. J. J. verbeek, n. vlassis, B. Kr\u00f6se, efficient greedy learning of gaussian mixture models. \nNeural Comput. 15, 469\u2013485 (2003).\n 67. F. Jelinek, c ontinuous speech recognition by statistical methods. Proc. IEEE 64, 532\u2013556 \n(1976).\n 68. t . Kamada, S. Kawai, An algorithm for drawing general undirected graphs. Information \nprocessing letters 31, 7\u201315 (1989).\n 69. c. Beattie, J. Z. l eibo, d . teplyashin, t. Ward, M. Wainwright, h. Kuttler, A. l efrancq,  \nS. Green, v. valdes, A. Sadik, J. Schrittwieser, K. Anderson, S. York, M. c ant, A. c ain,  \nDownloaded from https://www.science.org on October 12, 2024\nRaju et al., Sci. Adv. 10, eadm8470 (2024)     31 July 2024Science Adv AnceS  | ReSeAR ch AR ticle\n16 of 16A. Bolton, S. Gaffney, h. King, d . hassabis, S. l egg, S. Petersen, d eepmind lab. arXiv \npreprint arXiv:1612.03801 (2016).\nAcknowledgments: We thank M. Botvinick, K. Stachenfeld, d . Kumaran, c. Blundell, \nM. Shanahan, and d . hassabis for critically reading this manuscript and for insightful \ndiscussions. Funding: the authors acknowledge that they received no funding in support of \nthis research. Author contributions: c onceptualization: d .G. Methodology: M.l.-  G., R.v .R., \nJ.S.G., and d .G. investigation: R.v .R., J.S.G., c.W., M.l.-  G., and d .G. visualization: R.v .R. and d .G. \nSupervision: M.l.-  G. and d .G. Writing\u2014original draft: R.v .R., J.S.G., M.l.-  G., and d .G. Writing\u2014review and editing: R.v .R., J.S.G., G.Z., and d .G. Competing interests: the authors declare \nthat they have no competing interests. Data and materials availability: All data needed \nto evaluate the conclusions in the paper are present in the paper and/or the Supplementary \nMaterials.\nSubmitted 8 november 2023 \nAccepted 26 June 2024 \nPublished 31 July 2024 \n10.1126/sciadv.adm8470\nDownloaded from https://www.science.org on October 12, 2024\n",
    "process_text": "['Here is the list of concept-based snippets:\\n\\n[\\n    {\"concept\": \"CSCG Model\", \"text\": \"p(x,a)=... (23)\"},\\n    {\"concept\": \"Learning Procedure\", \"text\": \"Putting all together, the final learning procedure can then be summarized as follows:...\"},\\n    {\"concept\": \"CSCG Learning Stages\", \"text\": \"In our experiments, CSCG learning is typically performed in two stages: (i) EM learning and (ii) Viterbi learning....\"},\\n    {\"concept\": \"Soft EM and Viterbi Training\", \"text\": \"Soft EM in the first stage can result in multiple copies of the same graphs being learned in an interconnected and weighted manner, whereas the hard-EM (Viterbi) stage consolidates those copies.\"},\\n    {\"concept\": \"Computing Place Fields\", \"text\": \"Given a sequence of observations and actions, we define the activation of clone i at time n in a CSCG as the following marginal posterior probability...\"},\\n    {\"concept\": \"Hamming Distance Based Emission Matrix\", \"text\": \"We use a Hamming distance based emission matrix E(Ham) in Eq. 27, which is constructed as follows.\"},\\n    {\"concept\": \"Noisy or Uncertain Observations\", \"text\": \"In such cases, /u1D6C7xn can be a distribution over all possible observations.\"},\\n    {\"concept\": \"Place Fields Computation\", \"text\": \"To compute place fields in a given environment, we first obtain activations of the clones from N trials random walks of the agent, each of length Nlen time steps.\"},\\n    {\"concept\": \"Supplementary Materials\", \"text\": \"This PDF file includes: Supplementary text, Figs. S1 to S19, REFERENCES AND NOTES\"}\\n]\\n\\nLet me know if you\\'d like me to modify or refine the concept-based snippets in any way!', 'Here is the list of concept-based snippets in the required format:\\n\\n[\\n    {\"concept\": \"Place cell responses\", \"text\": \"Place cell responses are driven by their sequential contexts, and changes that substantially affect the sequential context of a neuron are what determines when and how its field will remap.\"},\\n    {\"concept\": \"Sequential context\", \"text\": \"Sequential context for a sensory observation can be thought of as the history of sensory observations that can predict it.\"},\\n    {\"concept\": \"CSCG model\", \"text\": \"The CSCG model makes this abstract definition concrete and measurable: Sequential context for a latent state is the temporal trajectories of latent states that lead to it.\"},\\n    {\"concept\": \"Place field remapping\", \"text\": \"Any change that makes the same sequential context occur in different parts of the room will result in that field partially appearing in the new place.\"},\\n    {\"concept\": \"Local context\", \"text\": \"The organization and specificity of local context driving the responses of a cell will have a notable impact on its remapping.\"},\\n    {\"concept\": \"Place cell anomalies\", \"text\": \"Anomalies have been accumulating over the simple view that place cells represent just locations.\"},\\n    {\"concept\": \"Place field mapping limitations\", \"text\": \"Place field mapping has served as a valuable tool in revealing the representational properties of neurons in the hippocampus, but it has limitations.\"},\\n    {\"concept\": \"Sequence-centric paradigm\", \"text\": \"The sequence-centric paradigm resolves these anomalies by re-interpreting space as a sequence.\"},\\n    {\"concept\": \"CSCG model advancements\", \"text\": \"Our current work required substantial advances over the previous work that introduced the basic CSCG model, including generalizing to egocentric setting and continuous high-dimensional signals from visual perception in 2D and 3D environments and arbitrary topologies.\"},\\n    {\"concept\": \"Implications for cognitive science and AI\", \"text\": \"Our work offers computational support for the Leibnizian view that only sequential ordering needs to be a priori, opening up interesting questions regarding innate representations and core knowledge for cognitive science and artificial intelligence (AI).\"}\\n]', 'Here is the structured concept-based snippets in the format of a Python list of dictionaries:\\n\\n```\\n[\\n    {\"concept\": \"Clonal selection\", \"text\": \"This kind of latent structure gives the flexibility to split the same observation in different sequential contexts or merge different temporal contexts into the same latent state.\"},\\n    {\"concept\": \"Learning latent topology\", \"text\": \"Learning the latent topology represented by P(zn+1|zn, an) is achieved using expectation maximization (EM), which maximizes the likelihood of the model using a local update mechanism.\"},\\n    {\"concept\": \"Initialization and overparameterization\", \"text\": \"The tensor P(zn+1|zn, an) is initialized randomly, and the number of latent states allocated is the \u201ccapacity\u201d of the model. Typically, the model is allocated excess capacity than what is needed to represent the environment.\"},\\n    {\"concept\": \"Splitting and merging latent states\", \"text\": \"The splitting and merging of latent states that is conceptually shown in Fig. 1B is achieved by the re-weighting of the connections by the EM updates without a change in the number of neurons.\"},\\n    {\"concept\": \"Biological plausibility\", \"text\": \"Our work focuses on the computational and algorithmic aspects of sequence learning in the brain and not on the actual implementation in neuronal networks. However, we do believe that inference and learning in CSCG can be achieved using biologically plausible mechanisms.\"},\\n    {\"concept\": \"Experimental settings\", \"text\": \"We tested the CSCG model in a variety of experimental settings. The first set of experiments investigated the ability of a CSCG to learn latent topologies from perceptually aliased observation sequences.\"},\\n    {\"concept\": \"Results\", \"text\": \"CSCGs are successful in learning latent topologies in a variety of environments, including two-dimensional (2D) and 3D simulated environments, from purely sequential aliased random walk observations.\"},\\n    {\"concept\": \"Place fields and head direction sensitivity\", \"text\": \"Examples of place fields are shown in Fig. 1Div. The clones in Fig. 1Diii are also head direction sensitive, which corresponds well with the observation in (32) that place fields show head direction sensitivity when they are mapped conditioned on head direction.\"},\\n]\\n```\\n\\nNote that some concepts may overlap or be related to each other, but I\\'ve tried to break down the text into distinct snippets based on the main ideas and concepts presented.', 'Here is the chunked text in the desired format:\\n\\n```\\n[\\n    {\"concept\": \"Barrier effects on place fields\", \"text\": \"One effect is that the barrier prevents the agent from taking some trajectories that are important for revealing the relevant sequential contexts for some clones. The second is that the presence of the barrier can change the visual sensation in its vicinity. Both these effects combine to explain why place fields are disrupted when a barrier is placed through its center, and not affected when the barrier is far away.\"},\\n    {\"concept\": \"CSCG and landmark vector remapping\", \"text\": \"CSCGs also explain why place cells can be seen as encoding a vector relationship to local landmarks (3 ). Just like cue cards, or boundaries, landmark objects placed in an environment act as disambiguating contexts with respect to which sensations at other locations are encoded. Thus, when a landmark is moved, some of sequential contexts also move in reference to that landmark.\"},\\n    {\"concept\": \"Place fields and track length variation\", \"text\": \"In more recent experiments (28), rats were trained on outbound and inbound traversals on a linear track that could be changed in length. Responses to the appropriate sequential contexts in a CSCG naturally explain the remapping of place fields observed as the track length varies.\"},\\n    {\"concept\": \"Sequence representation and spatial-temporal effects\", \"text\": \"Sequential contexts naturally explain the direction sensitivity of place field remapping reported in (27). When the room is elongated, some place fields that were unimodal in the original room remapped to produce two peaks, corresponding to two subcomponents in the elongated room.\"},\\n    {\"concept\": \"CSCG and event-specific rate remapping cells\", \"text\": \"CSCG can also explain recently discovered phenomena like event-specific rate remapping (ESR) cells (8), which signal a combination of location and lap number for different laps around a maze, without postulating special coding mechanisms.\"},\\n    {\"concept\": \"Predicting environmental changes and remapping\", \"text\": \"CSCGs show that environmental connectivity changes need not lead to place field remapping even when the agents\u2019 behavior shows adaptation to the change, a phenomenon that researchers found puzzling.\"},\\n]\\n```\\n\\nLet me know if this meets your requirements or if you need any further assistance!', 'Here is the structured concept-based snippets in the requested format:\\n\\n```\\n[\\n    {\"concept\": \"CSCG Learning\", \"text\": \"cSc G learning correctly learns separate maps for each maze.\"},\\n    {\"concept\": \"Reusable Schema\", \"text\": \"The learned transition graph of a cSc G trained on one environment can be considered a reusable schema.\"},\\n    {\"concept\": \"Place Cell Remapping\", \"text\": \"a sensation occurs explains a wide variety of place cell remapping phenomena.\"},\\n    {\"concept\": \"Sequential Interpretation of Spatial Representations\", \"text\": \"As we demonstrate, sequential interpretation of spatial representations can explain a variety remapping driven by changes in geometry, visual cues, transparent or opaque barriers, landmarks, distances to start or end locations, etc.\"},\\n    {\"concept\": \"Geometry Change-Driven Remapping\", \"text\": \"Changing the geometry of a room changes the locations where similar sequential contexts will be observed.\"},\\n    {\"concept\": \"CSCG Reproduction of Place Field Remapping Phenomena\", \"text\": \"A cSc G was first trained in a small square (SS) room and then tested in rooms with varying sizes and shapes.\"},\\n    {\"concept\": \"Directional Place Fields\", \"text\": \"The cSc G also replicated directional place fields reported in (27).\"},\\n    {\"concept\": \"Rotation of Place Fields\", \"text\": \"When trained in a circular room with a cue, the cSc G demonstrated that place fields also rotate when the cue is rotated.\"},\\n    {\"concept\": \"Landmark-Based Remapping\", \"text\": \"Trained in a rectangular layout with a landmark, the cSc G exhibited place fields with two components in the modified layout: one at the original location and another at a vector displacement from the new landmark location.\"},\\n    {\"concept\": \"Distance-Based Remapping\", \"text\": \"A cSc G was trained on a linear track using outbound and inbound walks. Place fields were computed using trials with different starting positions for the outbound trajectories and different end positions for the inbound trajectories.\"},\\n    {\"concept\": \"Lap-Based Remapping\", \"text\": \"A cSc G was trained in a rectangular maze similar to (8), with training trials comprising three laps followed by a reward at the end.\"},\\n    {\"concept\": \"Sequence Representation and Remapping\", \"text\": \"Remapping relies on changes in the environment being superposed on a previously learned graph without any new learning.\"},\\n    {\"concept\": \"CSCG Explanation of Muller and Kubie Experiments\", \"text\": \"The classic Muller and Kubie experiments (26) showing a variety of remapping phenomena can also be explained using CSCG, which we illustrate in Fig. 3B.\"}\\n]\\n```\\n\\nNote that some of the text snippets may overlap or be closely related, but I have tried to break them down into distinct concepts based on the original text.', 'Here is the structured concept-based snippets in the format of a Python list of dictionaries:\\n\\n```\\n[\\n    {\"concept\": \"Reevaluating Place Field Fidelity\", \"text\": \"Rather than treating place field fidelity as something the hippocampus is trying to achieve, our examples serve to demonstrate why place field mapping should be treated as just a visualization tool that the experimenter has at their disposal.\"},\\n    {\"concept\": \"Exploring New Avenues\", \"text\": \"We hope that this opens up a new avenue of exploration that takes us away from the familiar questions centered on encoding and decoding locations.\"},\\n    {\"concept\": \"Future Research Directions\", \"text\": \"Much remains to be explored on this new path we have struck out on. To demonstrate the viability of our theory, we selected a subset of the results from each of the experiments that we judged to be adequately representative. However, more can be done along this path.\"},\\n    {\"concept\": \"CSCGs and Hippocampal Research\", \"text\": \"We hope that our work gives a concrete tool that would help hippocampal researchers think beyond the place field paradigm.\"},\\n    {\"concept\": \"Expectation-Maximization Learning of CSCGs\", \"text\": \"The standard algorithm to train HMMs is the expectation-maximization (EM) algorithm, which in this context is known as the Baum-Welch algorithm.\"},\\n    {\"concept\": \"Cloned HMMs\", \"text\": \"Cloned HMMs, first introduced in (14), are a sparse restriction of overcomplete HMMs (18) that can overcome many of the training shortcomings of dynamic Markov coding.\"},\\n    {\"concept\": \"CSCGs: Action-Augmented Cloned HMMs\", \"text\": \"CSCGs are an extension of cloned HMMs in which an action happens at every time step (conditional on the current hidden state) and the hidden state of the next time step depends not only on the current hidden state but also on the current action.\"},\\n    {\"concept\": \"Learning a CSCG\", \"text\": \"Learning a CSCG requires optimizing the vector of prior probabilities \u03c0: \u03c0k = P(z 1 = k) and the action-augmented transition tensor T: Tijk = P(z n+1 = k\u2223, zn = j, an = i).\"}\\n]\\n```\\n\\nNote that some concepts may overlap or be related, but I have tried to break down the text into distinct, concept-based snippets.', 'Here is the chunked text in the requested format:\\n\\n```\\n[\\n    {\"concept\": \"Modified CSCGs and Navigation\", \"text\": \"connections appropriately, and planning routes in this modified CSCG corresponded to the reported successful navigation. We then computed place fields using the appropriately modified CSCGs paired with the arena connectivity changes, and compared these to the fields from the original CSCG in the original arena.\"},\\n    {\"concept\": \"Lack of Remapping\", \"text\": \"The reason for lack of remapping can be understood by realizing that the connectivity change blocked paths without any change in the visual cues. The blocked path affected only a few of the potential sequences that were responsible for that place field, a change that is too small to be reflected in the aggregated sequential responses.\"},\\n    {\"concept\": \"Dynamic Modification of CSCGs\", \"text\": \"While the explicit latent graph representation of CSCG allows for rapid structural modification of the internal model of an agent in response to environmental changes, the changes itself were manually made by the experimenter in the current results. Making these modifications automatically and dynamically in response to surprise would result in a further integrated model and is an area of further research.\"},\\n    {\"concept\": \"Sequence Learning and Place Fields\", \"text\": \"Sequence learning explains place field repetition, size, and shape variations. Place fields distort along the boundaries and increase in size systematically toward the center of an empty arena.\"},\\n    {\"concept\": \"Place Field Repetition\", \"text\": \"To demonstrate place field repetition in visually identical environments, we trained a CSCG in a layout comprising two visually identical rooms in the same orientation and connected by a corridor, as shown in Fig. 4B, similar to the setting in (29).\"},\\n    {\"concept\": \"Direction-Dependent Place Field Repetition\", \"text\": \"In Fig. 4D, we reproduce the direction-dependent place field repetition reported in (31). We trained a CSCG on a hairpin maze, with distinct end markers and a cue to distinguish top and bottom walls, using left to right (L \u2192 R) and right to left (R \u2192 L) walks.\"},\\n    {\"concept\": \"Room Size and Place Fields\", \"text\": \"To study the effect of room size on place fields (43), we trained three different CSCGs on square rooms, with uniform interiors, of side length 7, 9, and 11, respectively.\"},\\n    {\"concept\": \"Place Field Size Expansion\", \"text\": \"Place field size expansion (43) in an empty arena happens because of the same reason as place field repetition in two identical iso-oriented rooms.\"},\\n    {\"concept\": \"Testable Predictions of CSCGs\", \"text\": \"CSCGs can also make experimentally testable predictions for yet to be observed phenomena. One such prediction is the following. What controls how place fields change is not the rate of visual change, but the uniqueness of the visual context.\"},\\n    {\"concept\": \"Uniqueness of Visual Context\", \"text\": \"To demonstrate this, we trained two CSCGs on square rooms with checkerboard and random patterns on the floor, respectively. We observed that the place fields in the checkerboard room were more expanded, as shown in Fig. 4F.\"},\\n    {\"concept\": \"Mechanistic Explanation\", \"text\": \"CSCGs provide a mechanistic explanation for the question of when and why do place fields change in response to environmental changes.\"}\\n]\\n```\\nLet me know if you have any further requests!', 'Here is the chunked text in the requested format:\\n\\n```\\n[\\n    {\"concept\": \"CSCG (Cloned Subspace Clustering Graph)\", \"text\": \"submatrix T(u, v, w) contains the transition probabilities P(z n+1\u2223zn, an = u) for z n \u2208 C(v), zn+1 \u2208 C(w), where C(v) and C(w) correspond to the clones of emissions v and w, respectively.\"},\\n    {\"concept\": \"EM Algorithm for Learning CSCG\", \"text\": \"The EM equations for learning are also very similar: E-step, M-step. In (15), it was observed that the convergence of EM for learning the parameters of a CSCG can be improved by using a smoothing parameter called the pseudocount.\"},\\n    {\"concept\": \"Learning Emission Matrix with Transitions Fixed\", \"text\": \"With a CSCG, transfer learning between different environments can be accomplished by keeping its transition probabilities T fixed and learning the emissions associated to its nodes E in the new environment.\"},\\n    {\"concept\": \"EM Algorithm for Learning Emission Matrix\", \"text\": \"The EM algorithm can be used to learn the emission matrix as follows. The E-step recursively computes the forward and backward probabilities and then updates the posterior probabilities. The M-step updates only the emission matrix.\"},\\n    {\"concept\": \"CSCG Equations\", \"text\": \"\u03b1(1)=\u03c0 (x1)\u03b1(n+1)=T(xn,xn+1)\u22a4\u03b1(n ) (4) \u03b2(N )=1(xN)\u03b2(n)=T(xn,xn+1)\u03b2(n+1) (5) ...\"},\\n    {\"concept\": \"Learning Continuous CSCG\", \"text\": \"To extend CSCG to continuous observations, we introduced a new variable yn between the hidden state zn and the observation xn.\"},\\n    {\"concept\": \"Continuous CSCG Model\", \"text\": \"The joint distribution of a sequence of actions and continuous observations is ... where the observation model p(x n\u2223yn) = \ud835\udca9(x n\u2223\u03bcyn, \u03c32I) is parameterized as an isotropic Gaussian with variance \u03c32 and mean \u03bc yn, which is the centroid associated to the discrete emission y n.\"},\\n    {\"concept\": \"Parameter Optimization for Continuous CSCG\", \"text\": \"We find it simpler to proceed in two steps. In the first step, we fix P(z 1) = Tijk = 1/ \u2223Z\u2223, where \u2223Z\u2223 is the number of states in the hidden space, and learn \u03bc only.\"},\\n    {\"concept\": \"K-Means for Continuous CSCG\", \"text\": \"The astute reader will recognize Eq. 25 as the log likelihood of an isotropic Gaussian mixture model, which can be optimized greedily using K-means.\"},\\n    {\"concept\": \"Learning T for Continuous CSCG\", \"text\": \"In the second step, we keep \u03bc fixed as per the previous step and learn T by maximizing Eq. 24 w.r.t. T using EM.\"}\\n]\\n```\\n\\nNote that I\\'ve grouped the text into chunks based on the main concepts and ideas presented in the original text. Each chunk represents a distinct idea or concept, and the text associated with each chunk provides more details and explanations about that concept.', 'Here is the chunked text in the requested format:\\n\\n```\\n[\\n    {\"concept\": \"Relevance to AI\", \"text\": \"ideas in this paper have also become relevant for AI, addressing long-standing questions about episodic experience, memory, cognitive maps, and planning.\"},\\n    {\"concept\": \"Comparison to Temporal Context Models\", \"text\": \"While CSCG draws up on many past and contemporary models of hippocampus (47), it is markedly different in many aspects. In contrast to temporal context models (48) that accumulate sequential context in the observation space, the sequential representation in CSCG is in the latent space, giving it the ability to model more complex and long-duration temporal dependencies.\"},\\n    {\"concept\": \"Successor Representations\", \"text\": \"Although successor representations (49) can model temporal relations, they are not directly applicable in the aliased settings we consider here. Since successor representation assumes that sensations directly correspond to locations, it cannot explain how spatial representation emerges from egocentric sensations in the partially observable settings that animals encounter in the real world.\"},\\n    {\"concept\": \"Memory Compression Model\", \"text\": \"The memory compression model (50) focuses on compressing instantaneous inputs by exploiting correlations between them. However, their experiments are in a fully observable environment where the locations can be uniquely determined directly from the sensations, and sequence learning is not part of the model.\"},\\n    {\"concept\": \"Tolman-Eichenbaum Machines (TEMs)\", \"text\": \"Contemporary work on Tolman-Eichenbaum machines (TEMs) (51) has many similarities to CSCG in inspiration. However, unlike CSCG, TEMs do not learn latent graphs in aliased settings like ours.\"},\\n    {\"concept\": \"CSCG Advantages\", \"text\": \"A TEM is formulated purely as a predictive model, and its internal representation does not learn a modifiable graph that corresponds to the environment. Therefore, a TEM does not have the same ability as a CSCG to deal with dynamic environments quickly by changing its graph connectivity or to form hierarchies through community detection (53) on the latent graph as demonstrated in (15).\"},\\n    {\"concept\": \"Place Fields\", \"text\": \"Unlike other computational models of place fields, CSCGs do not use grid fields to learn place fields and still explain varied re-mapping phenomena.\"},\\n    {\"concept\": \"Robustness of CSCG\", \"text\": \"All the phenomena replicated in this work were robust without the need for careful handcrafting on the side of the experimenter.\"},\\n    {\"concept\": \"Learning Dynamics\", \"text\": \"Given sufficient capacity in the number of clones, CSCG learning was robust and converged to the ground-truth graph of the environment from random initializations.\"},\\n    {\"concept\": \"Multiple Maps\", \"text\": \"Another under-explored property of the CSCG is its ability to learn multiple maps of different fidelities and task contexts in the same model, and to dynamically switch between them based on contexts, just like switching between the maps of different arenas.\"},\\n    {\"concept\": \"Interpretation of Hippocampal Phenomena\", \"text\": \"The most important message from our work is that many of the diverse fascinating hippocampal phenomena might be artifacts of Euclidean place field mapping.\"},\\n    {\"concept\": \"Sequence Learning Model\", \"text\": \"By maintaining the same underlying model and altering the environments to align with neuroscience experiments, we demonstrate how distinct phenomena emerge solely from those environments.\"}\\n]\\n```\\n\\nLet me know if this meets your requirements or if you need any further assistance!', 'Here is the chunked text in the requested format:\\n\\n```\\n[\\n    {\"concept\": \"Agent Navigation\", \"text\": \"The agent itself has no mechanism by which it can derive a place field from the activity of its neurons. As we show in the next section, the agent does not need to compute place fields to locate itself, nor need to decode locations from the clones to make navigation decisions.\"},\\n    {\"concept\": \"CSCGs and Transitive Inferences\", \"text\": \"CSCGs make complex latent transitive inferences during learning and represent the learned information to enable transitive inferences (36). When different overlapping sections of an environment are exposed to the agent in disjoint episodes, CSCGs learn the underlying map that stitches together the whole environment (Fig. 2B), including the global loop closures.\"},\\n    {\"concept\": \"Map Representation and Recall\", \"text\": \"When environments are really disjoint, CSCGs learn to separate the maps, and simultaneously represent multiple maps in memory without being explicitly instructed about map boundaries during training (Fig. 2C). The appropriate map can then be recalled as hidden state inference (37) and used to guide behavior.\"},\\n    {\"concept\": \"Replay-Based Planning\", \"text\": \"A behaving agent can keep track of its state as the most likely clone given past observations, without having to invoke any concepts about space or place fields. If the agent intends to navigate to a previously remembered goal based on a visual sensation, the action sequences that achieve this can be directly inferred from the latent graph.\"},\\n    {\"concept\": \"Schema-Based Transfer\", \"text\": \"CSCGs can also transfer prior knowledge to new environments and infer shortcut paths through unobserved locations by treating the learned transition graph as a schema (40\u201342) and learning just the emission matrix.\"},\\n    {\"concept\": \"Advantages of CSCGs\", \"text\": \"A striking advantage of CSCG in comparison to such models is that learned maps can be quickly reconfigured to reflect changes in the environment. When a previously passable route is blocked, the corresponding structural modification can be made in the latent graph, and message passing\u2013based inference will use this updated information about the environment to navigate around obstacles (15).\"},\\n    {\"concept\": \"CSCGs and Place Fields\", \"text\": \"Remapping due to changes in overall geometry, visual cues, or landmarks can be explained using sequence learning. Changing the interpretation of place fields from explicitly representing spatial locations to representing the sequential context in which\"},\\n    {\"concept\": \"Experimental Results\", \"text\": \"See Table 1. List of experiments, their observed phenomena, and related publications.\"},\\n    {\"concept\": \"CSCG Learning and Environment\", \"text\": \"Fig. 2. CSCGs learn diverse latent topologies, transitively stitch them, and transfer structure to new environments. (A) cSc G learning in an example 3d environment. ...\"}\\n]\\n```\\n\\nNote that some of the text chunks are shorter or longer than others, depending on the natural boundaries of the concepts and ideas presented in the original text.', 'Here is the list of concept-based snippets:\\n\\n```\\n[\\n    {\"concept\": \"Introduction to the Hippocampus\", \"text\": \"The hippocampus is known for its role in episodic memory, map-like spatial representations, relational inference, and fast learning\u2014a seemingly disparate set of requirements.\"},\\n    {\"concept\": \"Diverse Phenomena in the Hippocampus\", \"text\": \"Simultaneously, hippocampal cells are categorized into a wide variety of types based on their firing patterns ranging from place cells, splitter cells, time cells, lap cells, and event-specific representations and exhibit a variety of re-mapping phenomena in response to environmental changes.\"},\\n    {\"concept\": \"Limitations of Euclidean Spatial Concepts\", \"text\": \"These phenomena often get characterized using Euclidean spatial concepts such as object vector cells, landmark vector cells, and distance coding, without a coherent underlying explanation, and remain unresolved with other phenomena like splitter cells and event-specific representations.\"},\\n    {\"concept\": \"The Need for a Unifying Principle\", \"text\": \"Could these divergent requirements and myriad phenomena be explained using a simple set of principles that are computationally grounded, implemented, and easy to understand?\"},\\n    {\"concept\": \"Treating Space as a Sequence\", \"text\": \"Here, we show that treating space as a sequence can resolve many of the divergent phenomena ascribed to spatial mapping, and help clarify the connections between spatial, temporal, abstract, and relational representations in the hippocampal complex.\"},\\n    {\"concept\": \"The Necessity of Sequence-Based Learning\", \"text\": \"Treating space as a sequence is a necessity for humans and other animals because they lack a global positioning system that enables direct sensing of location coordinates.\"},\\n    {\"concept\": \"The Problem of Aliased Sensations\", \"text\": \"Sensations from the world are aliased and do not convey locations directly. In other words, identical sensations can occur at multiple locations or in different sequential contexts.\"},\\n    {\"concept\": \"The Clone-Structured Causal Graph (CSCG) Model\", \"text\": \"Our model, clone-structured causal graph (CSCG), tackles this problem by learning different latent states to represent the same observation in different sequential contexts.\"},\\n    {\"concept\": \"Allocentric Representations from Sequence Learning\", \"text\": \"In CSCGs, allocentric \u201cspatial\u201d representations naturally arise from higher-order sequence learning on egocentric sensory and motor inputs, without making any Euclidean assumptions, and without having locations as an input.\"},\\n    {\"concept\": \"Limitations of Place Field Maps\", \"text\": \"Our model suggests that place field maps need to be interpreted carefully because they overlay sequential responses onto Euclidean maps.\"},\\n    {\"concept\": \"The CSCG Model\\'s Predictions\", \"text\": \"CSCGs predict the conditions under which place fields are expected to change in response to visible or invisible environmental changes, and when they do not, resolving a variety of phenomena with a simple principle.\"},\\n    {\"concept\": \"The Experimental Setup for the CSCG Model\", \"text\": \"We consider experimental setups where an agent moves around in an environment and receives local sensations that are aliased in the sense that they do not correspond uniquely to locations in the environment, and the actions of the agent are relative to its current orientation and not in a global frame.\"},\\n    {\"concept\": \"The Challenge of Learning Latent Topology\", \"text\": \"The environment need not be Euclidean. The agent makes no Euclidean assumptions and does not have access to a map of the environment. If the sensations from the environment are vectors, they are discretized using a vector quantizer.\"},\\n    {\"concept\": \"The Goal of the CSCG Model\", \"text\": \"From a sequence of discretized observations and actions, both of which could be egocentric, an agent has to discover the latent topology of its environment to vicariously evaluate different options for navigation.\"}\\n]\\n```', 'Here is the chunked text in the requested format:\\n\\n[\\n    {\"concept\": \"Agent-Environment Interaction\", \"text\": \"An agent performs a sequence of actions a 1, \u2026, a N (with each a n \u2208 {1, \u2026, N actions }) in an environment G.\"},\\n    {\"concept\": \"Observations\", \"text\": \"As a result of each action, it receives an observation, obtaining the stream x 1, \u2026, x N (with each x n \u2208 \u211dd or {1, \u2026, N obs} for continuous and discrete observations, respectively).\"},\\n    {\"concept\": \"Environment Definition\", \"text\": \"Concretely, an environment is defined by a directed multigraph G \u2261 {V, E} with latent nodes V \u2261 {v 1, \u2026v Nnodes } and latent edges E \u2261 {e1, \u2026e Nedges }.)\"},\\n    {\"concept\": \"Node Transitions\", \"text\": \"When an agent at latent node vi executes an action a, it will transition to v j with probability P(v j\u2223vi, a).\"},\\n    {\"concept\": \"Graph Properties\", \"text\": \"Whenever this probability is larger than 0, an associated directed edge from v i to v j is introduced in the graph, labeled with the corresponding action and probability.\"},\\n    {\"concept\": \"Cognitive Map Learning\", \"text\": \"The goal of learning is to recover the topology of the environment G from sequences of actions and observations.\"},\\n    {\"concept\": \"Clone-Structured Cognitive Graph\", \"text\": \"Fig. 1. Clone-structured cognitive graph. (A) learning cognitive maps from sequential sensory observations is challenging because observations do not identify locations uniquely.\\\\n(B) the cognitive map learning problem can be understood as learning a latent graph from observations emitted at every node, where two different nodes can emit the same observation.\"},\\n    {\"concept\": \"Cloning Structure\", \"text\": \"(C) the cloning structure of dynamic Markov coding can be incorporated in an hMM with a structured emission matrix, the cloned hMM. cSc G extends cloned hMMs by including actions.\"},\\n    {\"concept\": \"CSCG Model\", \"text\": \"The above definitions result in a precise, action-conditional probabilistic model for sequences.\"},\\n    {\"concept\": \"Probabilistic Graphical Model\", \"text\": \"Using z n to represent the unobserved node at time step n, and adding a simple per-node policy P(an\u2223zn) to also model the actions, results in the CSCG model.\"},\\n    {\"concept\": \"Joint Distribution\", \"text\": \"The joint distribution of a sequence of observations and actions is depicted as a probabilistic graphical model in Fig. 1C.\"},\\n    {\"concept\": \"Action-Conditional Transition Tensor\", \"text\": \"The transition probabilities are fully parameterized through an action-conditional transition tensor T with elements Tijk = P(z n+1 = k\u2223zn = j, an = i).\"},\\n    {\"concept\": \"Observation Model\", \"text\": \"In this formulation, the observation model p(x n\u2223yn) = \ud835\udca9(x n\u2223\u03bcyn, \u03c32I) is parameterized as an isotropic Gaussian with variance \u03c32 and mean \u03bc yn, which is the centroid associated to the discrete emission yn.\"},\\n    {\"concept\": \"Emission Model\", \"text\": \"The emission model is parameterized by an emission matrix E with elements E ij = P(yn = j\u2223zn = i).\"},\\n    {\"concept\": \"Clone Structure\", \"text\": \"In a CSCG, by design, multiple hidden states share the same emission: If states i and j are clones of the same emission, then p (y\u2223z = i) = p(y\u2223z = j).\"},\\n    {\"concept\": \"Hidden Markov Model\", \"text\": \"Observe that if we remove the policy P(an \u2223 zn) from Eq. 2, we are left with the conditional model p (x \u2223 a).\"},\\n    {\"concept\": \"Learning and Inference\", \"text\": \"The clone structure introduces a sparsity pattern in the emission matrix, which is computationally advantageous for both learning and inference.\"},\\n    {\"concept\": \"Causal Semantics and Interventions\", \"text\": \"In addition, the model supports causal semantics and learning from interventions.\"},\\n    {\"concept\": \"Transition Tensor and Environment Topology\", \"text\": \"For a given sequence of actions, the learned transition tensor P(zn+1\u2223zn, an) encodes a distribution over sequences, establishing a connection between observed temporal sequences and arbitrary hidden (not necessarily Euclidean) topologies G of the environment.\"}\\n]', 'Here is the list of concept-based snippets in the requested format:\\n\\n```\\n[\\n    {\"concept\": \"Egocentric to Allocentric Understanding\", \"text\": \"A. Banino, v. Zambaldi, d . Kumaran, d . hassabis, c. Barry, c. Blundell, A model of egocentric to allocentric understanding in mammalian brains.\"},\\n    {\"concept\": \"Distributed Representation of Temporal Context\", \"text\": \"M. W. howard, M. J. Kahana, A distributed representation of temporal context. J. Math. Psychol. 46, 269\u2013299 (2002).\"},\\n    {\"concept\": \"Hippocampus as a Predictive Map\", \"text\": \"K. l. Stachenfeld, M. M. Botvinick, S. J. Gershman, the hippocampus as a predictive map. Nat. Neurosci. 20, 1643\u20131653 (2017).\"},\\n    {\"concept\": \"Place Cells and Memory Compression\", \"text\": \"M. K. Benna, S. Fusi, Place cells may simply be memory cells: Memory compression leads to spatial tuning and history dependence. Proc. Natl. Acad. Sci. U.S.A. 118, e2018422118 (2021).\"},\\n    {\"concept\": \"Generalisation of Structural Knowledge\", \"text\": \"J. Whittington, t. Muller, S. Mark, c. Barry, t. Behrens, Generalisation of structural knowledge in the hippocampal- entorhinal system. Adv. Neural Inf. Process. Syst. 31, (2018).\"},\\n    {\"concept\": \"Efficient Inference in Structured Spaces\", \"text\": \"h. Sanders, M. Wilson, M. Klukas, S. Sharma, i. Fiete, efficient inference in structured spaces. Cell 183, 1147\u20131148 (2020).\"},\\n    {\"concept\": \"Statistical Learning of Temporal Community Structure\", \"text\": \"A. c. Schapiro, n. B. turk- Browne, K. A. norman, M. M. Botvinick, Statistical learning of temporal community structure in the hippocampus. Hippocampus 26, 3\u20138 (2016).\"},\\n    {\"concept\": \"Development of Spatial and Memory Circuits\", \"text\": \"h. M. tan, t. J. Wills, F. c acucci, the development of spatial and memory circuits in the rat. Wiley Interdiscip. Rev. Cogn. Sci. 8, e1424 (2017).\"},\\n    {\"concept\": \"Hippocampal Place Codes\", \"text\": \"M. P . Brandon, J. Koenig, J. K. l eutgeb, S. l eutgeb, new and distinct hippocampal place codes are generated in a new environment during septal inactivation. Neuron 82, 789\u2013796 (2014).\"},\\n    {\"concept\": \"Scale and Long-term Stability of Place Maps\", \"text\": \"c. S. Mallory, K. hardcastle, J. S. Bant, l. M. Giocomo, Grid scale drives the scale and long- term stability of place maps. Nat. Neurosci. 21, 270\u2013282 (2018).\"},\\n    {\"concept\": \"Developmental Switch in Place Cell Accuracy\", \"text\": \"l. Muessig, J. hauser, t. J. Wills, F. c acucci, A developmental switch in place cell accuracy coincides with grid cell maturation. Neuron 86, 1167\u20131173 (2015).\"},\\n    {\"concept\": \"Structured Scaffold Underlies Activity in the Hippocampus\", \"text\": \"d . Mulders, M. Y. Yim, J. S. l ee, A. K. l ee, t. taillefumier, i. R. Fiete, A structured scaffold underlies activity in the hippocampus. bioRxiv 2021.11.20.469406 [Preprint] (2016).\"},\\n    {\"concept\": \"Multiple Maps of the Same Spatial Context\", \"text\": \"l. Sheintuch, n. Geva, h. Baumer, Y. Rechavi, A. Rubin, Y. Ziv, Multiple maps of the same spatial context can stably coexist in the mouse hippocampus. Curr. Biol. 30, 1467\u20131476.e6 (2020).\"},\\n    {\"concept\": \"Local Sensory Cues and Place Cell Directionality\", \"text\": \"F. P . Battaglia, G. R. Sutherland, B. l. Mcnaughton, l ocal sensory cues and place cell directionality: Additional evidence of prospective coding in the hippocampus. J. Neurosci. 24, 4541\u20134550 (2004).\"},\\n    {\"concept\": \"From Cognitive Maps to Spatial Schemas\", \"text\": \"d . Farzanfar, h. J. Spiers, M. Moscovitch, R. S. Rosenbaum, From cognitive maps to spatial schemas. Nat. Rev. Neurosci. 24, 63\u201379 (2023).\"},\\n    {\"concept\": \"Active Inference and Planning\", \"text\": \"G. Pezzulo, e . cartoni, F. Rigoli, l. Pio- l opez, K. Friston, Active inference, epistemic value, and vicarious trial and error. Learn. Mem. 23, 322\u2013338 (2016).\"},\\n    {\"concept\": \"Data Compression and Gaussian Mixture Models\", \"text\": \"G. v. cormack, R. n. S. horspool, data compression using dynamic Markov modelling. Comput. J. 30, 541\u2013550 (1987).\"},\\n    {\"concept\": \"EM Algorithm and Convergence Properties\", \"text\": \"c. J. Wu, On the convergence properties of the em algorithm. Ann. Stat. 11, 95\u2013103 (1983).\"},\\n    {\"concept\": \"Greedy Learning of Gaussian Mixture Models\", \"text\": \"J. J. verbeek, n. vlassis, B. Kr\u00f6se, efficient greedy learning of gaussian mixture models. Neural Comput. 15, 469\u2013485 (2003).\"},\\n    {\"concept\": \"Continuous Speech Recognition\", \"text\": \"F. Jelinek, c ontinuous speech recognition by statistical methods. Proc. IEEE 64, 532\u2013556 (1976).\"},\\n    {\"concept\": \"Graph Drawing Algorithms\", \"text\": \"t . Kamada, S. Kawai, An algorithm for drawing general undirected graphs. Information processing letters 31, 7\u201315 (1989).\"}\\n]\\n```\\n\\nNote that some of the references are not necessarily concepts, but rather specific research papers or techniques. I\\'ve tried to group them into coherent concepts where possible.', 'The text provided appears to be a list of research papers and references related to neuroscience, cognitive science, and artificial intelligence. Chunking the text into structured concept-based snippets can be a subjective task, as it requires identifying the underlying concepts and themes present in the text. However, based on the content, I will attempt to break down the text into concept-based chunks. Here is the output in the desired Python list of dictionaries format:\\n\\n```\\n[\\n    {\"concept\": \"Hippocampal Place Cells\", \"text\": \"J. A. Ainge, M. tamosiunaite, F. Woergoetter, P . A. d udchenko, h ippocampal c A1 place cells encode intended destination on a maze with multiple choice points. J. Neurosci. 27, 9769\u20139779 (2007).\"},\\n    {\"concept\": \"Context-Dependent Hippocampal Activity\", \"text\": \"J. A. Ainge, M. A. A. van der Meer, R. F. langston, e . R. Wood, exploring the role of context-  dependent hippocampal activity in spatial alternation behavior. Hippocampus 17, 988\u20131002 (2007).\"},\\n    {\"concept\": \"Hippocampal Neurons\", \"text\": \"c. Sun, W. Yang, J. Martin, S. tonegawa, h ippocampal neurons represent events as transferable units of experience. Nat. Neurosci. 23, 651\u2013663 (2020).\"},\\n    {\"concept\": \"Space and Time in the Brain\", \"text\": \"G. Buzs\u00e1ki, R. llin\u00e1s, Space and time in the brain. Science 358, 482\u2013485 (2017).\"},\\n    {\"concept\": \"Learning to Perceive and Act\", \"text\": \"S. d. Whitehead, d . h. Ballard, l earning to perceive and act by trial and error. Mach. Learn. 7, 45\u201383 (1991).\"},\\n    {\"concept\": \"Task-State Representations\", \"text\": \"Y. niv, learning task- state representations. Nat. Neurosci. 22, 1544\u20131553 (2019).\"},\\n    {\"concept\": \"Experience-Dependent Contextual Codes\", \"text\": \"M. h. Plitt, l. M. Giocomo, experience-  dependent contextual codes in the hippocampus. Nat. Neurosci. 24, 705\u2013714 (2021).\"},\\n    {\"concept\": \"Higher-Order Sequential Structure\", \"text\": \"A. d edieu, n. Gothoskar, S. Swingle, W. l ehrach, M. l\u00e1zaro-  Gredilla, d . George, learning higher-  order sequential structure with cloned hMMs. arXiv:1905.00507 [stat. Ml] (2019).\"},\\n    {\"concept\": \"Cognitive Maps and Navigation\", \"text\": \"d . George, R. v. Rikhye, n. Gothoskar, J. S. Guntupalli, A. d edieu, M. l\u00e1zaro-  Gredilla, clone- structured graph representations enable flexible learning and vicarious evaluation of cognitive maps. Nat. Commun. 12, 2392 (2021).\"},\\n    {\"concept\": \"Hippocampus and Declarative Memory\", \"text\": \"h. eichenbaum, h ippocampus: c ognitive processes and neural representations that underlie declarative memory. Neuron 44, 109\u2013120 (2004).\"},\\n    {\"concept\": \"Non-Euclidean Navigation\", \"text\": \"W. h. Warren, non- e uclidean navigation. J. Exp. Biol. 222, jeb187971 (2019).\"},\\n    {\"concept\": \"Causal Inference and Learning\", \"text\": \"J. Pearl, Causality ( cambridge Univ. Press, ed. 2, 2013).\"},\\n    {\"concept\": \"Bayesian Computation and Neural Circuits\", \"text\": \"R. P . Rao, Bayesian computation in recurrent neural circuits. Neural Comput. 16, 1\u201338 (2004).\"},\\n    {\"concept\": \"STDP and Spike-Timing-Dependent Plasticity\", \"text\": \"B. nessler, M. Pfeiffer, l. Buesing, W. Maass, Bayesian computation emerges in generic cortical microcircuits through spike- timing-  dependent plasticity. PLOS Comput. Biol. 9, e1003037 (2013).\"},\\n    {\"concept\": \"Hippocampal Place Cell Remapping\", \"text\": \"M. c. Fuhs, S. R. vanRhoads, A. e . casale, B. Mcnaughton, d . S. touretzky, i nfluence of path integration versus environmental orientation on place cell remapping between visually identical environments. J. Neurophysiol. 94, 2603\u20132616 (2005).\"},\\n    {\"concept\": \"Grid Cell Maps and Spatial Memory\", \"text\": \"d . derdikman, J. R. Whitlock, A. tsao, M. Fyhn, t. hafting, M.- B. Moser, e . i. Moser, Fragmentation of grid cell maps in a multicompartment environment. Nat. Neurosci. 12, 1325\u20131332 (2009).\"},\\n    {\"concept\": \"Causal Influence of Visual Cues\", \"text\": \"l. Acharya, Z. M. Aghajan, c. vuong, J. J. Moore, M. R. Mehta, c ausal influence of visual cues on hippocampal directional selectivity. Cell 164, 197\u2013207 (2016).\"},\\n    {\"concept\": \"Heading Direction and Place-Cell Activity\", \"text\": \"P . e. Jercog, Y. Ahmadian, c. Woodruff, R. d eb- Sen, l. F. Abbott, e . R. Kandel, heading direction with respect to a reference point modulates place-  cell activity. Nat. Commun. 10, 2333 (2019).\"},\\n    {\"concept\": \"Linking Hippocampal Multiplexed Tuning and Navigation\", \"text\": \"J. J. Moore, J. d . cushman, l. Acharya, B. Popeney, M. R. Mehta, linking hippocampal multiplexed tuning, hebbian plasticity and navigation. Nature 599, 442\u2013448 (2021).\"},\\n    {\"concept\": \"Hippocampal Remapping as Hidden State Inference\", \"text\": \"h. Sanders, M. A. Wilson, S. J. Gershman, h ippocampal remapping as hidden state inference. eLife 9, e51140 (2020).\"},\\n    {\"concept\": \"Hippocampal Replay and Planning\", \"text\": \"h. F. \u00d3lafsd\u00f3ttir, d . Bush, c. Barry, the role of hippocampal replay in memory and planning. Curr. Biol. 28, R37\u2013R50 (2018).\"},\\n    {\"concept\": \"Schema Cells in the Macaque Hippocampus\", \"text\": \"P . Baraduc, J.- R. d uhamel, S. Wirth, Schema cells in the macaque hippocampus. Science 363, 635\u2013639 (2019).\"},\\n    {\"concept\": \"Geometric Transformation of Cognitive Maps\", \"text\": \"W. tang, J. d . Shin, S. P . Jadhav, Geometric transformation of cognitive maps for generalization across hippocampal-prefrontal circuits. Cell Rep. 42, 112246 (2023).\"}\\n]\\n```\\n\\nPlease note that the chunking is subjective and may vary based on individual perspectives and expertise. The concepts and texts provided are not exhaustive, and additional chunks may be identified upon further analysis.']"
  }
}